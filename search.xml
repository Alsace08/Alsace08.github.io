<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>无监督学习</title>
      <link href="/2022/07/22/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
      <url>/2022/07/22/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>文本摘要</title>
      <link href="/2022/07/22/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
      <url>/2022/07/22/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>链表刷题</title>
      <link href="/2022/07/17/%E9%93%BE%E8%A1%A8%E5%88%B7%E9%A2%98/"/>
      <url>/2022/07/17/%E9%93%BE%E8%A1%A8%E5%88%B7%E9%A2%98/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 题库 </tag>
            
            <tag> 链表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形态学：语言的词汇</title>
      <link href="/2022/07/17/%E5%BD%A2%E6%80%81%E5%AD%A6/"/>
      <url>/2022/07/17/%E5%BD%A2%E6%80%81%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文所述内容参考《语言引论》一书的第三章。</p></blockquote><p>词汇是语言知识的重要一环，并构成我们心理语法的一个组成部分。懂得一个词，就意味着知道某个特定的语音序列与特定的语义相关联。每个词都是一个音义结合的单位，因此我们的心理词库所储存的每个词必须列出其独特的语音表征，决定词的发音，并附上语义。</p><p>音义关系具有任意性。有些词发音相同，但意义不同（例如 bear 和 bare）；另一些词意义相同，但发音不同（例如 sofa 和 couch）。</p><h2 id="1-词典"><a href="#1-词典" class="headerlink" title="1 词典"></a>1 词典</h2><p>绝大多数词典，均以“规范”而非“描写”语词为己任。</p><p>对于词典中的每个词，都需要提供下列信息：（1）拼写；（2）标准发音；（3）一个或多个语义定义；（4）词性。</p><h2 id="2-实义词和功能词"><a href="#2-实义词和功能词" class="headerlink" title="2 实义词和功能词"></a>2 实义词和功能词</h2><ul><li><p>实义词：名词、动词、形容词、副词等我们可以加以考虑的事物、行为、属性、观念等概念，又称开放类词。</p></li><li><p>功能词：连词、介词、冠词、代词等用来界定语法关系，几乎没有语义内容的词汇，又称封闭类词。</p></li></ul><p>人脑处理功能词和实义词的方式不同，脑损害患者和其他有特定语言障碍的病人对于理解功能词，比理解实义词困难得多。</p><p>实义词用来表达语义，功能词则将实义词与更大的语法语境连成一体。两者在语言中各司其职。</p><h2 id="3-语素"><a href="#3-语素" class="headerlink" title="3 语素"></a>3 语素</h2><p>语素是<font color=Red>语法形式的最基本单位</font>，是语音和语义的任意结合体，是一切语言中最小的符号。一个语素可以是单个语音或多个音节，例如 a（单个语音）、child（单个音节）、water（两个音节）等。</p><p>一个词由一个或一个以上的语素构成，例如 im-possible，由两个语素构成。</p><p>用形态学来阐释语言创造性：我们既可以把一个词分解为其组成成分，对整词的词义进行理解或猜测，还可以将语素结合起来创造新词。</p><h3 id="3-1-黏着语素和自由语素"><a href="#3-1-黏着语素和自由语素" class="headerlink" title="3.1 黏着语素和自由语素"></a>3.1 黏着语素和自由语素</h3><p>形态学知识包含两个部分：（1）关于单个语素的知识；（2）关于语素结合规则的知识。</p><ul><li><p>自由语素：本身就构成词的语素，例如 boy、man。</p></li><li><p>黏着语素：永远不能自己构成词，但总是词的组成部分，是词缀。例如 -er、-ist。</p></li></ul><h4 id="3-1-1-前缀和后缀"><a href="#3-1-1-前缀和后缀" class="headerlink" title="3.1.1 前缀和后缀"></a>3.1.1 前缀和后缀</h4><p>词缀根据出现在其他语素的前面还是后面，分为前缀和后缀。</p><ul><li>同一种含义的语素，在不同语言下的规则方式不同。</li></ul><blockquote><p>在英语中，复数语素 -s 是后缀，但在墨西哥的伊斯姆斯-萨波特克语中，复数语素 -ka 是前缀。</p></blockquote><ul><li>同一个语素，在不同语言下含义不同。</li></ul><blockquote><p>语素 -ak 在土耳其语和卡罗克语（太平洋西北部岛屿上的一种美洲土著语）中的意义不同。在土耳其语中，表示将一个动词派生为名词，而在卡罗克语中，则表示将名词派生为副词，表示“在…里面”。</p></blockquote><p>同时进一步说明：<font color=Red>音义关系具有任意性</font>。</p><h4 id="3-1-2-中缀"><a href="#3-1-2-中缀" class="headerlink" title="3.1.2 中缀"></a>3.1.2 中缀</h4><p>一些语言中还存在中缀，即插入其他语素中间的语素。</p><blockquote><p>菲律宾的邦托克语中有这样一种中缀，-um- 插入名词或形容词的第一个辅音之后，用以将名词/形容词转化为动词，例如：fikas（强壮） —— fumikas（是强壮的）。</p></blockquote><p>英语的中缀通常只能将表达猥亵义的整个词插入另一个词中，最常见的 fuckin，插入后例如 un-fuckin-believable。</p><h4 id="3-1-3-外接缀"><a href="#3-1-3-外接缀" class="headerlink" title="3.1.3 外接缀"></a>3.1.3 外接缀</h4><p>一些语言中还存在外接缀，即在同一个词基语素的开头和末尾附加上的语素。</p><blockquote><p>德语中，规则动词的过去分词，通过在动词词根加上前缀 ge- 和后缀 -t 构成。例如：lieb（爱） —— geliebt（爱的过去分词）。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 语言学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 形态学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读 —— Adversarial Example Detection Using Latent Neighborhood Graph</title>
      <link href="/2022/07/17/LNG/"/>
      <url>/2022/07/17/LNG/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文探讨的论文标题为《Adversarial Example Detection Using Latent Neighborhood Graph》。文章标题开门见山，两个关键部分，一个是对抗样本检测（Adversarial Example Detection），这是描述了这篇文章所要完成的任务，另一个是潜在邻近图（Latent Neighborhood Graph），也就是说，文章很可能是要用一个图模型来完成样本检测的任务。带着这两个关键词，我们来详细分析一下这篇 ICCV 会议上的文章。</p></blockquote><p><img src="/pic/LNG/LNG-%E4%B8%BB.png" alt="LNG 概念图"></p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><h3 id="1-1-任务背景"><a href="#1-1-任务背景" class="headerlink" title="1.1 任务背景"></a>1.1 任务背景</h3><p>任务动机很朴素，当前的深度学习技术被广泛应用在了各个领域里面，但是一些攻击者会对整个深度模型进行操控，通过对模型的输入加入一些微小的扰动，来在人们难以察觉的情况下破坏整个模型的预测结果。这样的事情如果发生在一些安全系统当中，比如身份验证之类的重要环节，就会造成毁灭性的影响。因此深度模型的对抗训练必须被重视。</p><p><img src="/pic/LNG/%E4%BB%BB%E5%8A%A1%E8%83%8C%E6%99%AF.png" alt="一些深度模型微扰的例子，涉及cv、nlp等诸多领域"></p><h3 id="1-2-主流方法"><a href="#1-2-主流方法" class="headerlink" title="1.2 主流方法"></a>1.2 主流方法</h3><p>具体来说，为了让深度模型能够更好地去抵御这些扰动样本，目前比较主流的方法可以被归为两大类：主动防御和被动防御。</p><p>第一种是<font color=Red>主动防御</font>的方法。这种方法在模型训练中较为常见，即我们在训练时考虑到输入扰动的情况，然后手动加入一些对抗样本，这样能够提高模型的一个鲁棒性，而整个解空间更加平滑，而不会因为一个微扰让整个预测结果发生了根本性的变化。但是这种方法有一个非常关键的难点在于，它的训练代价比较大。试想一下，对于一个以及部署好了的已经被投放应用的模型，这时候说要让它的防御能力更强一点，势必要去重新训练整个模型，这个带来的代价是极大的，尤其是在真实的工业场景下。</p><p>另一种相对应的方法是<font color=Red>被动防御</font>方法。这种方式简单明了，不需要在训练时加入对抗样本提高鲁棒性，而是只需要在训练之前，就过滤出样本中的对抗样本即可。这样使得输入样本均为干净样本，训练出来的结果自然符合预期。这种方式对于已部署的系统来说很有价值，因为可以避免模型的重新训练。其次，它还可以帮助输入样本进行一次安全性检查，可以有效拦截一些不安全因素。</p><p>本文主要聚焦于被动防御方法，也就是对抗样本的检测。</p><h3 id="1-3-研究动机"><a href="#1-3-研究动机" class="headerlink" title="1.3 研究动机"></a>1.3 研究动机</h3><p>提到对抗样本检测，那就不得不提一下 Dknn 这个深度模型，这也是本文idea的一个核心的参考架构。</p><p>Dknn 是检测对抗样本的一个深度方法，它采用了 knn 的算法思想。我们要判断某个中心样本是否是对抗样本，首先将所有样本输入模型，之后在网络的每一层，每个样本都会得到一个 embedding。之后，沿用 knn 的思想，选择这个中心样本最相近的 k 个邻居，并将这 k 个邻居和中心样本的类别进行比较。如果这些样本基本属于同一类，说明这个中心样本不太可能是对抗样本，如果它们之间对应的类别有明显的不一致，例如，这个中心样本的类别是熊猫，但是它的 k 个邻居里面有一半是表示汽车的样本，那么这时候就可以怀疑这个中心样本可能存在问题。</p><p><img src="/pic/LNG/dknn.png" alt="DkNN 架构的核心思路示意图"></p><p>受到 Dknn 的启发，作者认为，Dknn 在检测对抗样本的时候，是利用了输入样本和它邻近样本之间的联系来判断的，那么可以利用一个动态的图结构，来更加具体地表示这种邻近关系。于是诞生了本文的核心模型，也就是 latent neighboorhood graph（以下简称LNG）。图模型的好处在于，它不光能够表示中心节点和它的邻近点，还能够通过建边来表示点和点之间的关系，这是 Dknn 方法做不到的。其次，把图模型构建出来之后，可以转化成一个二分类问题，利用图神经网络等方法进行分类。</p><h3 id="1-4-优势对比"><a href="#1-4-优势对比" class="headerlink" title="1.4 优势对比"></a>1.4 优势对比</h3><table>    <tr>        <td>LNG</td><td>Dknn</td>    </tr>    <tr>        <td>cover multi-hop heighbors of inputs’ local manifolds</td><td>only cover inputs’ local manifolds</td>    </tr>        <tr>        <td>richer information, aggregate the connectivity learned on the embedding space</td><td>only cover the information of class labels</td>    </tr>        <tr>        <td>incorporate both adversarial and benign neighbors</td><td>only utilize benign neighbors</td>    </tr></table><p>相比于dknn，LNG 的优势在于：<br>（1）图模型的信息表达更加丰富，它不光有节点的信息，也就是中心节点的邻居信息，还聚合了边的信息，也就是节点和节点之间的联系。我们可以通过距离来量化点和点之间的关联。<br>（2）LNG 引入了邻居多跳机制，可以把中心节点的邻居的邻居也给选择进来，让整个图模型的信息进一步丰富起来。</p><h2 id="2-方法架构"><a href="#2-方法架构" class="headerlink" title="2 方法架构"></a>2 方法架构</h2><h3 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h3><p>LNG 的方法流程如下所示：</p><p><img src="/pic/LNG/%E6%B5%81%E7%A8%8B.png" alt="LNG 方法流程图"></p><p>第一步，从完整的输入样本中提取出一个子集，称作是参考数据集，这个数据集的是用来构建图模型中的结点的，也就是图模型的结点范围不会超出这个参考数据集。</p><p>第二步，构建完数据集之后需要建图。建图分成两部分，首先是选择节点，其次是将点和点之间构建无向边，从而形成最终的图模型。</p><p>第三步，二分类问题，也就是判断中心节点是否是对抗样本。</p><h3 id="2-2-参考数据集"><a href="#2-2-参考数据集" class="headerlink" title="2.2 参考数据集"></a>2.2 参考数据集</h3><p>首先是参考数据集的构建。对于一个完整的数据集，从中提取出一个样本作为中心样本，我们需要判断这个样本是良性的还是对抗样本。之后，从这个完整的数据集中提取出一个样本子集，作为候选样本。</p><p>接下来有两种数据集的构建方法，第一种是直接把样本子集和中心样本给合起来，作为一个参考数据集，称为良性数据集。第二种是先对这个样本子集进行数据增强，也就是子集中的每个样本都利用对抗算法获得一个对抗样本，之后把扩充后的样本子集和中心样本合并起来，作为一个新的参考数据集，称为对抗数据集。</p><p><img src="/pic/LNG/reference_dataset.png" alt="参考数据集构建流程（自己画的）"></p><h3 id="2-3-潜在邻近图"><a href="#2-3-潜在邻近图" class="headerlink" title="2.3 潜在邻近图"></a>2.3 潜在邻近图</h3><p>接下来是核心步骤 —— 构图。</p><h4 id="2-3-1-结点构造"><a href="#2-3-1-结点构造" class="headerlink" title="2.3.1 结点构造"></a>2.3.1 结点构造</h4><p>首先是图节点的选择。对于中心节点来说，从参考数据集中选出最近的 k 个节点作为邻居。其次，引入了多跳邻居的思想，不仅可以选择中心节点的 k 邻近节点，还可以选择邻居的 k 邻近节点。具体来说，设置一个阈值 L，表示可以迭代的邻居次数。例如 L=2，就可以选择中心节点的邻居，这是一轮，以及邻居的邻居，这是第二轮，那 L=3,4 以此类推，相当于一个广度优先搜索的思想。但是所有选出的点不会超出参考数据集的范围。</p><h4 id="2-3-2-边构造"><a href="#2-3-2-边构造" class="headerlink" title="2.3.2 边构造"></a>2.3.2 边构造</h4><p>接下来是节点之间边的表示，主要还是利用欧氏距离来进行表征，并且为了归一化尺度，用 sigmoid 函数做了一个映射，将边权映射到0到1的区间上。此外，这个 sigmoid 函数中有两个参数 $t$ 和 $\theta$，是放在网络中用来学习的参数。</p><p>$$<br>A_{i,j} = \frac{1}{1 + e^{-t \cdot d(i,j) + \theta}}<br>$$</p><h3 id="2-4-图分类器"><a href="#2-4-图分类器" class="headerlink" title="2.4 图分类器"></a>2.4 图分类器</h3><p>最后一部分是图分类器，用来判定中心节点是良性样本还是对抗样本。文章采用的是经典的图注意力网络模型 GAT，模型的输入是所有样本的 embedding 以及邻接矩阵，输出是一个二维向量。</p><h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h2><h3 id="3-1-实验设置"><a href="#3-1-实验设置" class="headerlink" title="3.1 实验设置"></a>3.1 实验设置</h3><p>实验共采用了 5 种经典的对抗样本生成方法，包括 FGSM，PGD 等，这是在构建参考数据集的时候，对原数据做数据增强用的。Baseline 主要用了 DKNN 和 KNN 架构，以及 LID 和Hu 等人提出的方法。数据集采用了图像领域经典的几个数据集，包括有 CIFAR-10，ImageNet 和 STL-10。</p><h3 id="3-2-实验细节"><a href="#3-2-实验细节" class="headerlink" title="3.2 实验细节"></a>3.2 实验细节</h3><p>对于每个数据集，分成三个部分：训练集、参考集和测试集，这里的参考集是用来选取超参数的，比如多跳邻居机制里面的参数 L。验证集是从测试集里单独划分出来的，例如对于CIFAR-10 数据集，本实验从测试集中，每个类别随机选了 100 个样本组成了新的验证集。此外，同一个数据集上只能用一种对抗攻击方法，以及在主实验中，使用的是加入对抗样本的参考数据集。</p><p>超参数设置方面，主要是多跳邻居机制的阈值 L 和 knn 算法里面的 k。文章设置了 L=2，k=5。还有一个是 baseline 里面的dknn算法，也要有具体 k 值的设置。实验在三个数据集上的 k 值设置分别为200，40 和 40。</p><p>最后是对于 LNG 图的输出结果的处理。在训练过程中，所有的边的结果是通过欧氏距离和sigmoid 映射来产生的。从模型输出之后，所有的边的信息又被映射为一个 0-1 空间。具体来说，如果这条边的大小大于某个阈值 t，那么认为这条边存在，赋值为 1，否则认为不存在，赋值为 0。</p><h3 id="3-3-threat-model"><a href="#3-3-threat-model" class="headerlink" title="3.3 threat model"></a>3.3 threat model</h3><h4 id="3-3-1-白盒测试"><a href="#3-3-1-白盒测试" class="headerlink" title="3.3.1 白盒测试"></a>3.3.1 白盒测试</h4><h4 id="3-3-2-黑盒测试"><a href="#3-3-2-黑盒测试" class="headerlink" title="3.3.2 黑盒测试"></a>3.3.2 黑盒测试</h4><h3 id="3-4-主实验"><a href="#3-4-主实验" class="headerlink" title="3.4 主实验"></a>3.4 主实验</h3><h4 id="3-4-1-检测已知攻击"><a href="#3-4-1-检测已知攻击" class="headerlink" title="3.4.1 检测已知攻击"></a>3.4.1 检测已知攻击</h4><h4 id="3-4-2-检测未知攻击"><a href="#3-4-2-检测未知攻击" class="headerlink" title="3.4.2 检测未知攻击"></a>3.4.2 检测未知攻击</h4><h3 id="3-5-消融实验"><a href="#3-5-消融实验" class="headerlink" title="3.5 消融实验"></a>3.5 消融实验</h3><h3 id="3-6-图的拓扑结构讨论"><a href="#3-6-图的拓扑结构讨论" class="headerlink" title="3.6 图的拓扑结构讨论"></a>3.6 图的拓扑结构讨论</h3>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 对抗机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读 —— BERT：Pre-training of Deep Bidirectional Transformers</title>
      <link href="/2022/07/17/bert/"/>
      <url>/2022/07/17/bert/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文所探讨的论文标题为 《BERT：Pre-training of Deep Bidirectional Transformers for Language Understanding》</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022计算机保研记录 | 夏令营经历分享</title>
      <link href="/2022/07/16/%E4%BF%9D%E7%A0%941/"/>
      <url>/2022/07/16/%E4%BF%9D%E7%A0%941/</url>
      
        <content type="html"><![CDATA[<h2 id="0-写在前面的话"><a href="#0-写在前面的话" class="headerlink" title="0 写在前面的话"></a>0 写在前面的话</h2><h2 id="1-个人背景"><a href="#1-个人背景" class="headerlink" title="1 个人背景"></a>1 个人背景</h2><ul><li><p>本科院校：北京航空航天大学</p></li><li><p>专业：人工智能 </p></li><li><p>排名（前五学期）：3/31（10%）</p></li><li><p>英语：CET-4 581，CET-6 549</p></li><li><p>竞赛&amp;荣誉：数竞、蓝桥杯省一，美赛H，若干校级科创竞赛奖项，以及校级和企业奖学金</p></li><li><p>科研&amp;项目：两段科研经历，均为自然语言处理方向。一篇 ICDM（DM, CCF-B） 二作，一篇 COLING（NLP，CCF-B） 一作，夏令营时均为在投状态；无横向项目经历</p></li></ul><p>根据我参加夏令营的经验，个人认为在<font color=Red>初审阶段</font>，各项指标的重要程度大致排序为：院校 $\approx$ 排名 &gt; 科研 &gt; 竞赛 &gt; 英语，这里的竞赛指的是数学、数模，包括蓝桥杯等普通编程类竞赛，但是如果是 ACM 竞赛，其含金量应该等同于一项优质的科研经历。</p><p>那么就我个人的背景而言，首次，最占优的是本科院校和科研经历。本科就读于中上游 985，科研经历较为丰富，且不是类似于大创、互联网+这种横向课题经历，而是真正的研究经历，且方向较为纯粹，始终聚焦于自然语言处理（这也是我研究生阶段坚定选择的研究方向）。其次，竞赛和英语平平无奇，四六级不高不低，竞赛也都是省级奖项，没有什么有含金量的国家级奖项，整体不加分也不减分。最后是排名，这是我整个背景的一大劣势，且这一劣势在初审阶段十分致命。由于疫情原因，大多数夏令营采取了线上的形式，因此海投现象非常严重。于是，不少院校会采用直接筛选排名的方式来初步过滤简历，这对于 10% 的排名来说，简直是有苦说不出。这项劣势在初审阶段也确实得到了验证，例如复旦和人大这两所强com学校，都是大概率因为排名的原因未通过初审。</p><h2 id="2-夏令营报名情况"><a href="#2-夏令营报名情况" class="headerlink" title="2 夏令营报名情况"></a>2 夏令营报名情况</h2><p>我在夏令营阶段共计投递 18 个院系，入营 9 个，参营 6 个（包含 1 个不发放 offer 的清华计算机系），获得 offer 4 个。具体情况罗列如下。</p><table>    <tr>        <th>院校/研究所</th><th>院系/专业</th><th>报考层次</th><th>入营</th><th>offer</th><th>备注</th>    </tr>    <tr>        <td rowspan="2">清华大学</td><td>计算机系</td><td>不区分硕博</td><td>√</td><td></td><td>不发放offer，机试前50%直通预推免</td>    </tr>    <tr>        <td>深圳研究生院-信息科学与技术学部（AI项目）</td><td>专硕</td><td>√</td><td>√</td><td></td>    </tr>    <tr>        <td rowspan="3">北京大学</td><td>计算机学院</td><td>硕士</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>智能学院</td><td>硕士</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>深圳研究生院</td><td>硕士</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>复旦大学</td><td>计算机科学与技术学院</td><td>学硕</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>上海交通大学</td><td>电子信息与电气工程学院</td><td>直博</td><td>√</td><td>√</td><td>已提前联系好导师</td>    </tr>    <tr>        <td>中国人民大学</td><td>高瓴人工智能学院</td><td>学硕</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td rowspan="2">中国科学技术大学</td><td>计算机科学与技术学院</td><td>不区分硕博</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>大数据学院</td><td>不区分硕博</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td rowspan="2">南京大学</td><td>人工智能学院</td><td>硕士</td><td>√</td><td>×</td><td>笔试未通过</td>    </tr>    <tr>        <td>计算机科学与技术系</td><td>硕士</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td rowspan="4">中科院</td><td>自动化研究所</td><td>不区分硕博</td><td>√</td><td>√</td><td>获得专硕和直博选择权</td>    </tr>    <tr>        <td>计算技术研究所</td><td>不区分硕博</td><td>√</td><td></td><td>vipl实验室（nlp方向），通过一轮考核，后放弃</td>    </tr>    <tr>        <td>软件研究所</td><td>不区分硕博</td><td>√</td><td>√</td><td>中文信息处理实验室，提前面试获得offer</td>    </tr>    <tr>        <td>深圳先进研究院</td><td>不区分硕博</td><td>×</td><td></td><td></td>    </tr>    <tr>        <td>北京师范大学</td><td>人工智能学院</td><td>不区分硕博</td><td>√</td><td></td><td>放弃参营</td>    </tr>        <tr>        <td>西湖大学</td><td>工学院</td><td>直博</td><td>√</td><td></td><td>放弃参营</td>    </tr>    </table><p>总体来说，我最担心的初审环节，似乎并没有预期那么糟糕（因为排名 10% 太拉垮），入营率 50%。最意外的是清华和自所，在报名阶段最不抱希望的两个营，结果全部通过初审（最后都获得 offer），尤其是清华，居然贵系和清深双入，可能对于清华来说，反而不是唯 GPA 论的初筛方式。最难过的是人大高瓴，本来以为稳入，结果被拒。最遗憾的是复旦，我的夏令营第一目标就是复旦的 nlp 组，结果复旦是我第一个被拒的营，直接让我的希望破灭（因为 nlp 组的名额在夏令营必定被抢光，预推免不会留坑）。</p><p>整体过程十分感慨，不到最后一刻，永远不知道会有什么惊喜。<font color=Red>那些你觉得毫无希望的营，可能没有你想象的那么难，那些你觉得稳进的营，也可能有更厉害的人把你卷下去。</font></p><h2 id="3-参营记录"><a href="#3-参营记录" class="headerlink" title="3 参营记录"></a>3 参营记录</h2><h4 id="7-2-7-3-清华大学-计算机系"><a href="#7-2-7-3-清华大学-计算机系" class="headerlink" title="7.2-7.3 清华大学 计算机系"></a>7.2-7.3 清华大学 计算机系</h4><p>清华贵系的夏令营不发 offer，只有机试环节，机试排名靠前可以获得直通预推免面试的资格。因此，我并没有把重心放在贵系上，只是抱着体验的态度去参加。贵系的机试极其硬核，算是全国高校 cs 夏令营里面独一档的难度，可以说就是为 ACMer 准备的。况且进入贵系夏令营的有很多 ACM 选手，因此我这种没有任何算法竞赛基础的，只能是当一当分母。</p><p>贵系机试共 3 道题，总时长 3 小时，满分 300。第一题比较送分，关于图论和拓扑排序，基本上 10 min AC。后两题开始坐牢，都是和树有关的题目，最后一题可能是一道树形 DP + 各种优化，我想了半天也没有想出正解，最后暴力搜索骗了一些分。最后以 130 分收场。当然，不出所料没有拿到直通预推免资格。据某绿群群友所说，大概今年需要达到 170 分左右，才可能通过机试。</p><p>结果：未获得直通预推免资格</p><h4 id="7-2-7-5-清华大学-深圳国际研究生院（信息科学与技术学部AI项目）"><a href="#7-2-7-5-清华大学-深圳国际研究生院（信息科学与技术学部AI项目）" class="headerlink" title="7.2-7.5 清华大学 深圳国际研究生院（信息科学与技术学部AI项目）"></a>7.2-7.5 清华大学 深圳国际研究生院（信息科学与技术学部AI项目）</h4><p>清深是我收到的第一个获得入营资格的夏令营，也是参加的第一个真正意义上的夏令营。在此特地“表扬”一下清深招办，在半夜三点二十发来了入营通知。果然清华这种高校半夜都是不睡觉工作的吗（？）</p><p>首先介绍一下清深，全称为深圳国际研究生院，是清华大学下属的一个院系，而不是分校区，因此你的学籍是留在清华本部的，说到底就是清华大学的学生（虽然在民间可能认可度存在差异）。清深的培养以就业为导向，地处深圳这块 IT 风水宝地，学生在研究生阶段基本以实习为主，因此就业前景十分广阔，但是科研氛围相对不够浓厚。清深信息学部的学位均为专硕（0854电子信息），无学硕，因此在报考时，需要慎重考虑是否能够接受。</p><p>清深的夏令营考核一向以硬核著称，往年据说都是组队做项目，答辩通过之后才能进入面试。初试的考核以实验室为单位，一共分为 5 个实验室，可以自由选择 1-2 个实验室参加对应的初试考核，之后组内竞争面试资格。AI 学部的实验室方向很杂，网络、机器人、知识图谱、CV等等应有尽有，因此入营的学生也很杂，来自五花八门的专业。我选择了唯一一个跟我研究兴趣匹配的实验室 —— 知识工程研究中心。该实验室也是唯一一个不用组队完成项目的，考核方式为笔试 + 机试。</p><p>7.3 全天实验室考核。笔试内容包含数学、机器学习、深度学习、AI 前沿进展等相关知识，共 16 道大题，包含简答和计算。其中，前八题为数学题，基本为概率论计算题，考察较细，难度不低。后八题是 AI 相关，知识点涉及贝叶斯分类、K-means、SVM、反向传播等，以及一些前沿知识了解，整体考察较为全面。机器学习、深度学习相关的考题对我而言基本没有什么难度，概率论相关计算题因为很久很久没有碰过了，做起来比较吃力，空了不少。最后估摸着能考到 75-80/100 的样子。机试内容三道编程题，两小时，分别为线段树、动态规划和搜索+优化（maybe），需要有一定的算法基础。机试实时公布得分排名，我最终获得了 250/300 分，排名第一。机试完成后，我基本能确定自己可以通过初试了。</p><p>7.4 晚公布了入围面试的名单，总共 90 人，入围了 54 人，通过率刚好 60%。这里忍不住批评一下清深的办事效率，大半夜十二点半发来面试通知的邮件，结果我被安排在了早八面试。好不容易熬到了通知准备睡觉，结果一点多钟接到清深的电话，提醒我明早面试……真是又好气又好笑，虽然确实很负责，但是这办事效率和办公时间也太阴间了吧……夏令营体验直接大幅度下降。</p><p>7.5 全天面试，我被分到了第一个。面试共两部分，第一部分英文考核（5min），随机抽一段英文文章，限时朗读并翻译。第二部分是导师问答，首先 5-7 min 自我介绍，之后英文+中文提问。清深的提问基本根据你的简历和初审提交的材料来进行，关于英文提问，我被问到了个人的研究兴趣以及我的论文中的一个名词解释，中文提问相对没有很硬核，会偏向于聊天的形式。几个老师围在一张桌子前，轮流发问，提问内容包括但不限于一些科研细节、研究计划、有没有报其他地方的夏令营等，以及一个老师看我研究 nlp，问了我一个 BERT 相关的问题，我基本上都能对答如流。但是面试过程中有一段让我印象深刻，一个老教师对着我的成绩单，问我军事理论这门课为什么考这么低（问完之后其他老师都笑了）。当时愣了一下，没想到会被问到这个奇怪的问题，很快意识到可能被压力面了，于是整理了一下思路从容交待。之后他又看到我的成绩单上有三门离散数学课，然后就问了我一个群论的问题，我如实回答说没学过，并解释了一下这三门离散分别学了什么。老师很讶异，又问了我一个图论问题，让我解释一下“欧拉树”。结果这个概率我又刚好没学过…于是只能很尴尬地承认也没学过。之后老师就没有再追问下去。</p><p>虽然有这么一个尴尬的小插曲，但是整体面试很顺利，我跟老师之间的交流比较顺畅，没有任何磕绊的地方。面试完当天下午，意外的收到了知识工程研究中心发来的消息，向我抛出了橄榄枝，询问我去清深的意愿，并且愿意给我本部 tj 老师的招生名额。过了大概两周，tj 老师组那边亲自联系了我，说我在夏令营中的表现特别好，让我进组一段时间，看看双方是否合适。然而，…</p><p>总体来说，清深 AI 的优营率不算高，估计在 20% - 30% 的样子。不得不说，清深的报名网站是我见过的所有报名系统中 UI 设计最美观的（不愧是清华大学），最后还有一个很像 928 系统确认的这么一个确认环节，感觉很有仪式感hhh。</p><p><img src="/pic/%E4%BF%9D%E7%A0%94/%E6%B8%85%E6%B7%B1%E9%A2%84%E5%BD%95%E5%8F%96.jpg" alt="清深AI预录取资格"></p><p>结果：获得预录取offer</p><h4 id="7-7-南京大学-人工智能学院"><a href="#7-7-南京大学-人工智能学院" class="headerlink" title="7.7 南京大学 人工智能学院"></a>7.7 南京大学 人工智能学院</h4><p>南大 AI 是我唯一一个参营但未通过考核的院系。南大 AI、CS 和 SE 都是首先需要进行笔试，通过笔试初筛才能够进入面试环节。南大是出了名的海王营，笔试的作用其实就是帮助老师进行一个初筛的过程。南大在夏令营初审阶段会放大量的学生入营（就这样我还没入 CS 营），之后统一笔试。</p><p>笔试由大量的选择题和若干填空简答构成，总时长 90min。涉及知识点包括线代、概率论、数理统计、数据结构、机器学习、深度学习等若干科目，其中不乏概念理解题和计算题，要求知识点掌握必须全面。整体来说难度不小，也基本无从准备。</p><p>两三天后出结果，发现没收到笔试通过的邮件，G 了，属实意料之外。不过本身并没有太想去南大 AI，也就作罢。</p><p><strong>结果：笔试一轮游，未进入面试阶段</strong></p><h4 id="7-8-7-10-上海交通大学-电子信息与电气工程学院"><a href="#7-8-7-10-上海交通大学-电子信息与电气工程学院" class="headerlink" title="7.8-7.10 上海交通大学 电子信息与电气工程学院"></a>7.8-7.10 上海交通大学 电子信息与电气工程学院</h4><p>上交的夏令营算是华五里面最难入营的一个，据说每年直硕只招 985 rank 1-2。因此，有自知之明的我直接放弃了直硕的想法（因为排名只有 10%），而是提前联系了一位 nlp 方向的青椒，并点明了跟随他读博的意愿。在六月份的时候，我和老师联系过 3-4 次，在一些学术问题上有过一些简单的 proposal 交流（因为是直博，老师希望双方提前对彼此都有更深的了解）。交流几次之后，老师对我的个人情况以及能力都比较满意，也承诺说愿意在夏令营阶段把我捞上岸，希望双方能够成功匹配上。</p><p>上交的直博面试相对偏重为一个形式，因为需要与导师达成双选后，学院才会颁发优营，而面试只需要 60 分及格，就可以进入师生双选阶段。因此，上交直博的关键在于联系导师，导师直接决定你是否获得 offer。面试主要针对英语和科研经历提问，一个面试组中，对你的研究领域不熟悉的老师可能会偏重于问专业课，对你的领域熟悉的老师会深究科研细节。面试一共 20min，首先是 5min 带 PPT 的自我介绍，介绍结束后是英文问答，问到了我三个关于论文的问题，分别是论文的 reaseach direction、novelty 和 difficulty。</p><p><strong>结果：进入师生双选环节</strong></p><h4 id="7-11-7-15-中科院自动化研究所"><a href="#7-11-7-15-中科院自动化研究所" class="headerlink" title="7.11-7.15 中科院自动化研究所"></a>7.11-7.15 中科院自动化研究所</h4><p>自所是我认为办的最好的一个夏令营，它真的是按照“夏令营”的模式来办的。前三天是各个实验室导师代表的讲座，介绍各实验室的情况以及研究进展。同时，还安排了每个实验室单独的师生交流会，以及自所学生的经验分享会。总之是干货满满。</p><p>自所是典型的强 com 院校，入营全凭自身简历。今年据说一共报名了 2600 多人，入营约 300 个，形势基本持平往年。但是自所的优营率很高，据说前 40 % 学硕、直博和专硕任选，40% - 60% 只能专硕，60% - 80% 候补，最后 20 % 淘汰。再加上入营之后会有一些人直接放弃考核，因此只要不是过于拉垮，基本都能拿到 offer。自所的考核形式也是比较特殊。首先将所有学院分为若干组，然后组内竞争名额，每个组内学生的院校背景比较平均。我们组一共 27 人，其中 24 个 985，剩余 3 个 211，且院校基本无重复。</p><p>最后两天是面试时间，每个人 12min，包括 1min 自我介绍，3min 数学英语测试，8min 专业问答。之前一直听说自所很喜欢问数学，而且问的比较细，但实际面试时发现并没有想象中那么可怕。我抽到的数学问题是列举一些离散型概率分布，以及举一个伯努利分布的例子，还算是比较平稳。专业问答环节基本围绕简历提问，问到一些科研细节，以及在科研方面的开放型问题，一些见解和看法。同时，也会就你的竞赛经历进行一些提问，我的简历上因为写到了蓝桥杯，所以问了我一个问题“什么是动态规划”。除此之外，没有问到任何专业知识的内容，剩下就是简单的唠家常环节。</p><p>大约五天之后出了结果，拿到了直博和专硕的任选权。其实对于中科院来说，个人认为直博比硕士更香。因此，我并不遗憾没有拿到学硕资格。</p><p><strong>结果：获得直博/专硕 offer</strong></p><h4 id="7-18-7-22-中科院软件研究所"><a href="#7-18-7-22-中科院软件研究所" class="headerlink" title="7.18-7.22 中科院软件研究所"></a>7.18-7.22 中科院软件研究所</h4><p>虽然名字叫软件所，但是其中不乏一些研究软件之外的实验室，例如比较出名的中文信息处理实验室（以下简称“中文实验室”），每年都是软件所最火的实验室之一。这也是我此行唯一的目的。早在五月初，中文实验室便开放了报名通知，我也是早早地投出了简历。之后过了两个月，直到七月初，才收到实验室的考核通知，首先第一轮是机试环节。</p><p>7.4 参加了第一轮机试，在牛客平台上进行。机试一共 8 道题，总时长 90 min，分值为两题 10 分，三题 30 分，三题 40 分，计分规则为选取最高得分的三题计入总分。机试难度适中，涉及动态规划、二叉树、单调栈、大模拟等若干知识点，整体思维量较小，对算法要求不算很高。我在前 70 min 拿下了 110 分，就直接退出考试了。当然，很顺利地通过了机试。</p><p>大约有 12 人通过了一轮机试，进入到第二轮的面试环节。7.11 参加了第二轮面试，面试分为两个阶段，第一阶段是导师问答，首先用 PPT 进行一个五分钟的自我展示，之后导师提问，一般是对着简历上的内容问一些细节，之后也会唠一些家常，询问一些读研读博的意愿之类的，就我而言没有问到任何专业课知识。第二阶段是手撕代码，考核老师给一道题目，要求先叙述思路，若思路正确，则共享电脑屏幕，用任意语言在任意 IDE 上实现具体代码。问到我的是一个数组划分问题，将一个数组分成两个子数组，要求两个子数组各自的和之差最小。简单思索之后，我想出了一个类似 0-1 背包的解法，整体还算比较顺利。</p><p>结果在第二天下午收到了实验室学长的微信消息，说是实验室的 s 老师想找我面谈（一开始以为我在北京，想约我线下）。当时就感觉基本稳了，果不其然，s 老师先是给我介绍了一些实验室的基本情况，之后让我随便提问，以增进了解为目的，并且明确表示了给我发放 offer 的意愿。在聊天过程中我也了解到，第一轮面试中的 12 个人里面，实验室只选出了 2 个人通过了考核，这也让我十分惊喜，感觉自己的能力得到了老师们的一致认可。</p><p>后续 7.18 开营，我就直接免去了机试和面试的环节。当然，根据实验室要求，在 7.20 的时候补测了一场笔试，其实是英语考核，包含阅读、写作等内容。总之，我的软件所之旅在开营之前，就已经完美收官了。</p><p><strong>结果：提前获得实验室 offer，夏令营免试</strong></p><h4 id="7-19-7-22-中科院计算技术研究所"><a href="#7-19-7-22-中科院计算技术研究所" class="headerlink" title="7.19-7.22 中科院计算技术研究所"></a>7.19-7.22 中科院计算技术研究所</h4><p>计算所的考核方式很特别，采用实验室考核制。因此，这是一个典型的弱 com 院校，只要获得了实验室导师的考核邀请，甚至可以不用入营，也能够参与考核。当然，这就要求提前联系好导师，因为导师话语权巨大。</p><p>在填报夏令营时，除了填报系统之外，还会让你填报两个意愿导师，并且榜单实时更新公示。因为我是 nlp 方向的，因此选择了计算所唯一一个做 nlp 的 fy 老师。事实证明，物以稀为贵，再加上 vipl 实验室自身的加成，fy 老师成为今年最火爆的导师，填报人数超过 70 人（可能更多）。</p><p>不过很荣幸收到了 vipl 实验室的考核通知，最后参与考核的人数为 35 人。事实证明，强组不仅考核难度大，考核过程还十分折腾。下面展示一下具体考核流程。</p><p><img src="/pic/%E4%BF%9D%E7%A0%94/%E8%80%83%E6%A0%B8%E5%AE%89%E6%8E%92.png" alt="vipl-nlp方向 考核安排"></p><p><img src="/pic/%E4%BF%9D%E7%A0%94/%E8%80%83%E6%A0%B8%E5%86%85%E5%AE%B9.png" alt="vipl-nlp方向 考核内容"></p><p>7.19 先参加了第一轮笔试，考核内容为数学90min + 算法60min + 英语60min。数学考试共六个大题，前两题比较送分，一个特征值计算，一个概率计算。后面四道题开始上难度，据我个人回忆分别是严格最值点证明、随机游走、梯度恒等式证明、矩阵范数最值等相关问题，对数学水平要求很高，绝不仅仅是做一些作业题或者考研题就能掌握的，需要较高的数学能力来支撑。总之我在考场上做懵了，后四题完整地写了两题（也不知道正确与否），还有两题基本没动。</p><p>算法考核给了五个题目，要求分别写出算法思路，以及相应的时间复杂度。感觉难度分化比较大，涉及贪心、动态规划、图论、二分等若干知识点。前两题也是基本送分，后三题需要较强的算法基础和思维能力。我在考场上一共做出了前三题，后两题纯暴力写法，时间复杂度直接上天。</p><p>英语考核共三部分，第一部分翻译，一个中译英，一个英译中。第二部分摘要，给出了一段论文段落，要求写一个 200 词的英文摘要，和 400 字的中文摘要。给的那篇文章是生物信息学相关的，因为没有相关知识基础，只能逐词逐句硬翻，这也是我耗时最多的一个题目。最后一部分是用 150 词的英文介绍自己上过的一门课。因为平时经常读英文文献的缘故，这样的开放式写作对我来说基本上问题不大，10 min 就完成了写作。</p><p>总体而言，数学和算法难度大，英语题量大，题型新，没有一门是顺利完成的。第一轮笔试应该是刷掉一半的人进入下一轮，当天晚上接到通知，成功通过了第一轮考核。然而不幸的是，由于第二天上午软件所笔试的冲突，我不得不在两者之间进行选择。因为此时我已经拿到了中文信息实验室的offer，如果这时候鸽掉，未免过于遗憾。于是我做了一个决定，放弃了后续 vipl 的考核，中途弃赛退出。</p><p>至此，我的夏令营之旅全部结束。</p><p><strong>结果：通过第一轮笔试，后放弃考核</strong></p>]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保研夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hpctoolkit安装与使用</title>
      <link href="/2022/01/19/hpctoolkit/"/>
      <url>/2022/01/19/hpctoolkit/</url>
      
        <content type="html"><![CDATA[<h2 id="Source-Code-Installation"><a href="#Source-Code-Installation" class="headerlink" title="Source Code Installation"></a>Source Code Installation</h2><p>We now use Spack for building HPCToolkit’s prerequisites (replacing the old hpctoolkit externals). You can install HPCToolkit with the “One Button” spack install hpctoolkit method.</p><ul><li>Clone Spack Repositories on GitHub.</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;spack&#x2F;spack<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>Create Environment Variables</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export SPACK_ROOT&#x3D;&#96;pwd&#96;&#x2F;spackexport PATH&#x3D;$&#123;SPACK_ROOT&#125;&#x2F;bin:$PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>Refresh Shell Environment</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">source $&#123;SPACK_ROOT&#125;&#x2F;share&#x2F;spack&#x2F;setup-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>Check the Build Environment</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spack compiler find<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>Install</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spack install hpctoolkit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Typical-bug"><a href="#Typical-bug" class="headerlink" title="Typical bug"></a>Typical bug</h2><p><img src="/pic/bug1.png" alt="avatar"></p><p><img src="/pic/bug2.png" alt="avatar"></p><ul><li><p>Reasons</p><p>  fortran build environment is not set</p></li><li><p>Solution</p><p>  Add the build environment to <code>/.spack/linux/compilers.yaml</code></p></li></ul><p><img src="/pic/bug.png" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> 并行计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高性能分析工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>

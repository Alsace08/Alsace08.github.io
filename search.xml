<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>textcnn</title>
      <link href="/2022/07/31/textcnn/"/>
      <url>/2022/07/31/textcnn/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>pytorch 中常见的 tensor 操作</title>
      <link href="/2022/07/31/tensor-operation/"/>
      <url>/2022/07/31/tensor-operation/</url>
      
        <content type="html"><![CDATA[<p><img src="/pic/tensor.png" alt="scalar - vector - tensor"></p><blockquote><p>我们在训练深度网络时，不可避免地会涉及到对张量（tensor）的操作，例如维度变换、数据填充等。每种操作都在 torch 库中有对应的函数，然而，由于操作种类繁多，我们很难记住所有命令并将其区分开来，且容易造成混淆。因此，本文罗列了若干常用的张量操作命令及对应的参数设置，方便以后在进行深度模型的部署时进行查询调用。</p></blockquote><h2 id="1-单个张量的维度操作"><a href="#1-单个张量的维度操作" class="headerlink" title="1 单个张量的维度操作"></a>1 单个张量的维度操作</h2><p>对于单个张量的操作，常见的有维度的变形、扩张、压缩，以及在指定维度下的填充等操作。</p><h3 id="1-1-维度变形"><a href="#1-1-维度变形" class="headerlink" title="1.1 维度变形"></a>1.1 维度变形</h3><blockquote><p>torch.view(shape)：新旧张量数据元素相同，但是尺寸不同</p></blockquote><ul><li>shape - 变形后的尺寸</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.randn(4, 4, 2)print(a.size())     # torch.Size([4, 4, 2])a &#x3D; a.view(2, 16)print(a.size())     # torch.Size([2, 16])a &#x3D; a.view(8, -1)print(a.size())     # torch.Size([8, 4])a &#x3D; a.view(8, 3)print(a.size())     # RuntimeError: shape &#39;[8, 3]&#39; is invalid for input of size 32<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>注：若某一维度的 shape 为 -1 ，则自动计算维度后填充，如例 3</li></ul><h3 id="1-2-维度压缩"><a href="#1-2-维度压缩" class="headerlink" title="1.2 维度压缩"></a>1.2 维度压缩</h3><blockquote><p>torch.squeeze(input, dim=None, out=None)：除去输入张量 input 中维数为 1 的维度。例如，输入张量维度为 (a * 1 * b * c * 1)：（1）若不指定维度 dim 的具体数值，则返回张量的维度为 (a * b * c)；（2）若指定维度，当对应维度的维数为 1，则在对应维度上压缩，例如 dim = 1，当对应维度的维数不为 1，则不进行压缩操作，例如 dim = 0。</p></blockquote><ul><li>input (Tensor) – 输入张量</li><li>dim (int, optional) – 如果给定，则只会在给定维度压缩</li><li>out (Tensor, optional) – 输出张量</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.randn(4, 4, 1, 2, 1)a &#x3D; torch.squeeze(a)print(a.size())     # torch.Size([4, 4, 2])a &#x3D; torch.randn(4, 4, 1, 2, 1)a &#x3D; torch.squeeze(a, dim&#x3D;2)print(a.size())     # torch.Size([4, 4, 2, 1])a &#x3D; torch.randn(4, 4, 1, 2, 1)a &#x3D; torch.squeeze(a, dim&#x3D;1)print(a.size())     # torch.Size([4, 4, 1, 2, 1])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-维度扩展"><a href="#1-3-维度扩展" class="headerlink" title="1.3 维度扩展"></a>1.3 维度扩展</h3><blockquote><p>torch.unsqueeze(input, dim=None, out=None)：有维度压缩，就有维度扩展，即对输入张量 input 的指定维度插入维数 1。</p></blockquote><ul><li>tensor (Tensor) – 输入张量</li><li>dim (int) – 插入维度的索引</li><li>out (Tensor, optional) – 输出张量</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.randn(4, 4, 2)print(a.size())     # torch.Size([4, 4, 2])a &#x3D; torch.unsqueeze(a, dim&#x3D;1)print(a.size())     # torch.Size([4, 1, 4, 2])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-维度填充"><a href="#1-4-维度填充" class="headerlink" title="1.4 维度填充"></a>1.4 维度填充</h3><blockquote><p>torch.nn.functional.pad(input, pad, mode=’constant’, value=0)：不改变维度，仅改变维度数值，在某个维度上进行参数的扩充</p></blockquote><ul><li>pad - 扩充维度，预先定义出某维度上的扩充参数（具体见示例）</li><li>mode - 扩充方法：’constant’, ‘reflect’ 和 ‘replicate’ 三种模式，分别表示常量，反射，复制</li><li>value - 扩充时指定补充值，仅在 mode = ‘constant’ 时有效</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">import torch.nn.functional as Fa &#x3D; torch.zeros(2, 2, 1)print(a)# tensor([[[0.],#          [0.]],#         [[0.],#          [0.]]])print(a.size())# torch.Size([2, 2, 1])a &#x3D; torch.zeros(2, 2, 1)a &#x3D; F.pad(a, pad&#x3D;(1, 2), mode&#x3D;&#39;constant&#39;, value&#x3D;1)  # 在倒数第一个维度上，左边填充 1 个维数，右边填充 2 个维数print(a)# tensor([[[1., 0., 1., 1.],#          [1., 0., 1., 1.]],#         [[1., 0., 1., 1.],#          [1., 0., 1., 1.]]])print(a.size())# torch.Size([2, 2, 4])a &#x3D; torch.zeros(2, 2, 1)a &#x3D; F.pad(a, pad&#x3D;(1, 2, 2, 1), mode&#x3D;&#39;constant&#39;, value&#x3D;1)    # 在倒数第一个维度上，左边填充 1 个维数，右边填充 2 个维数；在倒数第二个维度上，左边填充 2 个维数，右边填充 1 个维数print(a)# tensor([[[1., 1., 1., 1.],#          [1., 1., 1., 1.],#          [1., 0., 1., 1.],#          [1., 0., 1., 1.],#          [1., 1., 1., 1.]],#         [[1., 1., 1., 1.],#          [1., 1., 1., 1.],#          [1., 0., 1., 1.],#          [1., 0., 1., 1.],#          [1., 1., 1., 1.]]])print(a.size())# torch.Size([2, 5, 4])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/pic/tensor/Fpad.png" alt="torch.nn.functional 中的 padding 操作示意图"></p><h3 id="1-5-维度置换"><a href="#1-5-维度置换" class="headerlink" title="1.5 维度置换"></a>1.5 维度置换</h3><blockquote><p>torch.permute(dims)：对张量进行对应维度上的置换，维数值不变。</p></blockquote><ul><li>dims：指定换位顺序，例如 dims=(1, 0, 2)，则维度 0 和维度 1 置换顺序。</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.randn(6, 3, 7)print(a.size())     # torch.Size([6, 3, 7])a &#x3D; x.permute(2, 0, 1)print(a.size())     # torch.Size([7, 6, 3])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-多个张量的维度操作"><a href="#2-多个张量的维度操作" class="headerlink" title="2 多个张量的维度操作"></a>2 多个张量的维度操作</h2><p>对于多个张量的操作，常见的有张量之间的拼接与拆分。</p><h3 id="2-1-维度合并"><a href="#2-1-维度合并" class="headerlink" title="2.1 维度合并"></a>2.1 维度合并</h3><h4 id="2-1-1-不产生新维度"><a href="#2-1-1-不产生新维度" class="headerlink" title="2.1.1 不产生新维度"></a>2.1.1 不产生新维度</h4><blockquote><p>torch.cat(input, dim)：将两个相同维度的张量合并成一个新的张量。想要拼接的维度上的数值可以不同，但其余维度上的数值应完全一致</p></blockquote><ul><li>input：输入张量</li><li>dim：按照维度 dim 进行合并</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.rand(4, 32, 8)b &#x3D; torch.rand(5, 32, 8)c &#x3D; torch.cat([a, b], dim&#x3D;0)print(c.size())     # torch.Size([9, 32, 8])a &#x3D; torch.rand(4, 32, 8)b &#x3D; torch.rand(5, 32, 8)c &#x3D; torch.cat([a, b], dim&#x3D;1)print(c.size())     # RuntimeError: Sizes of tensors must match except in dimension 1. Got 4 and 5 in dimension 0 (The offending index is 1)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-1-2-产生新维度"><a href="#2-1-2-产生新维度" class="headerlink" title="2.1.2 产生新维度"></a>2.1.2 产生新维度</h4><blockquote><p>torch.stack(input, dim)：将若干维度相同，每个维度的数值也相同的张量合并成一个新的张量，并在最外层扩张一个新的维度，该维度的维数即为合并的张量的数目</p></blockquote><ul><li>input：输入张量</li><li>dim：按照维度 dim 进行合并</li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">a &#x3D; torch.rand(32, 8)b &#x3D; torch.rand(32, 8)c &#x3D; torch.rand(32, 8)d &#x3D; torch.stack([a, b, c], dim&#x3D;0)print(d.size())     # torch.Size([3, 32, 8])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-维度拆分"><a href="#2-2-维度拆分" class="headerlink" title="2.2 维度拆分"></a>2.2 维度拆分</h3><blockquote><p>torch.split(split_size, dim=0)：将一个张量在某个维度上进行拆分，拆分后该维度上的数值发生改变，其余维度的数值不变</p></blockquote><ul><li><p>split_size</p><ul><li>如果是一个数字 num，表示将维度为 dim 中的值按照 num 平均拆分成多个 tensor；</li><li>如果是一个列表 [num1, num2, num3, …]，表示将维度为 dim 中的值按照该列表进行分配，生成指定个数的 tensor</li></ul></li><li><p>dim：按照维度 dim 进行拆分</p></li></ul><pre class="line-numbers language-py" data-language="py"><code class="language-py">d &#x3D; torch.rand(6, 32, 8)a, b, c &#x3D; d.split([3, 2, 1], dim&#x3D;0)print(a.size())     # torch.Size([3, 32, 8])print(b.size())     # torch.Size([2, 32, 8])print(c.size())     # torch.Size([1, 32, 8])# 能够整除d &#x3D; torch.rand(6, 32, 8)a, b &#x3D; d.split(3, dim&#x3D;0)print(a.size())     # torch.Size([3, 32, 8])print(b.size())     # torch.Size([3, 32, 8])# 无法整除，则取余d &#x3D; torch.rand(6, 32, 8)a, b &#x3D; d.split(4, dim&#x3D;0)print(a.size())     # torch.Size([4, 32, 8])print(b.size())     # torch.Size([2, 32, 8])# 报错示例 1 d &#x3D; torch.rand(6, 32, 8)a, b, c &#x3D; d.split(3, dim&#x3D;0)print(a.size())print(b.size())print(c.size())# ValueError: not enough values to unpack (expected 3, got 2)# 报错示例 2d &#x3D; torch.rand(6, 32, 8)a, b &#x3D; d.split([3, 2, 1], dim&#x3D;0)print(a.size())print(b.size())# ValueError: too many values to unpack (expected 2)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>在报错示例 1 中我们发现，该拆分操作旨在将 dim=0 上的 6 降为 3，因此只能拆分出 6/3 = 2 个张量。而在赋值语句中，我们设置了 a, b, c 三个张量，由于无法拆分出这么多张量，故返回报错结果。</li><li>在报错示例 2 中我们发现，该拆分操作返回三个张量结果，而我们设置的函数接收值仅有两个，故返回报错结果。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LSTM+CRF 实现命名实体识别任务</title>
      <link href="/2022/07/28/LSTM-CRF/"/>
      <url>/2022/07/28/LSTM-CRF/</url>
      
        <content type="html"><![CDATA[<p><img src="/pic/LSTM+CRF.jpg" alt="LSTM+CRF 模型架构图"></p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 序列标注 </tag>
            
            <tag> 命名实体识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无监督学习</title>
      <link href="/2022/07/22/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
      <url>/2022/07/22/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>浅谈自动摘要生成任务</title>
      <link href="/2022/07/22/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/"/>
      <url>/2022/07/22/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81/</url>
      
        <content type="html"><![CDATA[<p><img src="/pic/Automatic-Summarization.png" alt="自动文本摘要生成"></p><h2 id="1-抽取式摘要"><a href="#1-抽取式摘要" class="headerlink" title="1 抽取式摘要"></a>1 抽取式摘要</h2><blockquote><p>抽取式摘要任务本质上已经变成了一个序列标注任务，即对每个句子打标签，判定这个句子到底要不要被放在摘要里面。当然，这里的标注不一定是标注整个句子，也可以是一些更细粒度的特征，后面会介绍几个相应的算法。对于通用模型架构而言，首先是 encoder，经过句子级别的 encoder 和文档级别的 encoder，获得原文句子和文章级别的 embedding 表征。之后是 decoder，利用输出的摘要语句和原文的语义编码，来映射到对应的序列标注，获取最终抽取的结果。</p></blockquote><p><img src="/pic/summarization/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8.png" alt="序列标注任务：encoder-decoder 架构"></p><h3 id="1-1-基于句子的抽取"><a href="#1-1-基于句子的抽取" class="headerlink" title="1.1 基于句子的抽取"></a>1.1 基于句子的抽取</h3><p>比较常用的是 RNN 和 Transformer 的架构。RNN 的这篇文章在构建文档级别的语义表征的时候，不仅利用了句子级别的含义表征，还掺杂了一些其他的元素，比如句子的显著性、新颖性、绝对和相对位置等因素，通过词嵌入的形式加入在最终的表征里面。之后 Transformer 出现，Transformer 就取代了 RNN 成为了新的主流架构。Bertsum 这篇文章，是利用 Bert 模型在摘要任务上面做的微调。它是将每个句子开头的 CLS 字符的词嵌入作为整个句子的表征，经过 BERT 输出之后，新建了一个摘要层，用来微调抽取式摘要任务，它里面给了 MLP、RNN、Transformer 三种类型的架构。这也是Transformer 架构用在抽取式摘要上的一个主流方法，直到现在很多做抽取式摘要的还把它作为 baseline 来对比实验。</p><p><img src="/pic/summarization/RNN+transformer.png" alt="（左）SummaRuNNer，即 RNN 架构；（右）BertSum，即 Transformer 架构"></p><p>这是两个主流架构，并没有引入过多的摘要任务的归纳偏置，之后的很多研究也继续在抽取句子这个级别上做了很多延展性的工作，主要还是基于<font color=Red>如何表征句子的语义</font>，让句子表征蕴含更多有价值的信息。我们可以看下这篇文章，这是 20 年 ACL 上的一篇抽取式摘要的文章，它仍然是对原文中句子层面的内容进行的抽取，但是在进行句子表征时，加入了一个叫做关键词的内容。因为一个句子中肯定存在很多不重要的信息，关键的东西就那么几个，比方说人物、地点之类的，那它的思路就是要把每个句子中的关键词信息充分地融在句子表征当中，首先构建了一个叫做 nerual topic 的 model 来提取句子中的关键词，之后对关键词和句子构建图模型，最后利用图神经网络对图中的句子结点进行分类，获得句子的序列标注。近两年来这种图模型的方法不断地涌现出来，包括复旦大学之前做过几篇也是用图来构建摘要文本的，这里不赘述。图模型对于文本及其之间的关联，能够非常好的表现出来。</p><p><img src="/pic/summarization/graphsum.png" alt="GraphSum 模型架构"></p><h3 id="1-2-基于子句的抽取"><a href="#1-2-基于子句的抽取" class="headerlink" title="1.2 基于子句的抽取"></a>1.2 基于子句的抽取</h3><p>句子层面的抽取做到这个地步很难继续深入了，所以相关研究人员开始不满足于句子的抽取，把思路转向了更加细粒度的方法，比如说将一个句子拆分若干子句，然后标注子句是否被提取。这里介绍两个模型，一个是 DiscoBert，这个模型的思想跟上面 GraphSum 比较像，也是构图，只不过那个是构建的句子中的关键词和句子之间的图，并且只对句子结点进行标注，但这个模型是把句子拆成子句，然后构建子句之间的图模型，并且对子句进行了序列标注，在粒度上更细了一步。</p><p>它的子句采用了 RST 树来进行提取，是一种句法分析树，利用句法分析来获取子句之间的关系。之后还是先用 Transformer 对每个子句进行编码，然后把图模型放进图神经网络里面进行结果预测，得到最终每个子句的标注。</p><p><img src="/pic/summarization/DiscoBert.png" alt="GraphSum 模型架构"></p><p>同样的，还有一个 SSE 模型，也是做了子句粒度上的抽取。这个似乎更加简单，它甚至没有构图，纯粹是用句法树抽了一下子句（基于 Penn Treebank），然后放进 Transformer 里面做了一个二分类任务。</p><p><img src="/pic/summarization/SSE.png" alt="SSE 模型架构：（左）子句抽取；（右）二分类编码器"></p><p>所以我们发现，如果这个提取的粒度是介于词语和整句之间的，大多数现有的工作都是通过一些基础性的句法分析模型来获取句子结构，之后构建子句之间的联系来回归到原有的 RNN 或者 Transfomer 框架之中。</p><h3 id="1-3-混合粒度抽取"><a href="#1-3-混合粒度抽取" class="headerlink" title="1.3 混合粒度抽取"></a>1.3 混合粒度抽取</h3><p>当然，如果粒度更细一点的话，可能就不需要做这些预处理的工作（句法分析等），比如说这一篇名叫 swap-net 的工作，它是考虑了句子粒度和词语粒度这两个混合粒度。也就是说，在抽取的摘要中，可能会同时包含原文中的整句和词语，因为原文中可能会有一些很重要的关键词，如果放在整句当中，它的重要性可能不会那么显著，甚至会被忽视，为了避免这种现象的出现，它在 Decoder 解码时设计了一个交换机制。每一步的解码进行一个判定，判定抽取原文中的句子还是词语。如果抽句子，给原文中的所有句子输出一个概率分布，然后选取概率最高的句子，如果抽词语，同理给词语输出概率分布。这样一个交换机制，能够使得抽取的摘要在保证语法和逻辑完整的同时，嵌入了更多重要的关键词。</p><p><img src="/pic/summarization/swapnet.png" alt="Swap-net 模型架构"></p><h3 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h3><p>总结了这些关于抽取式摘要的方法，不管是抽整句也好，还是抽子句、抽词语，总之现在的方法正在不断地往更细粒度的方向去发展，更加注重模型对于句间逻辑关系，表述灵活性等等方面的表征。但是我在调研的时候并没有发现纯抽词语的方法，就算是抽词语，像上面提到的swap-net，也是边抽词语边抽句子的。</p><p>究其原因，个人认为，首先抽取式摘要相比较生成式摘要的一个最大的优势，便是我们从原文中抽取出的句子，至少是合乎语法并且逻辑通顺的，唯一需要处理的是句子和句子之间的关联是否足够强，以及信息冗余的问题，这是生成式摘要所具有挑战性的任务。生成式摘要由于是从词表里面抽词语，所以拼成的句子合不合语法与逻辑还要另说。那对于抽取式摘要来说，如果单抽词语，那它的最大优势，也就是合乎语法以及句内逻辑通顺，就利用不上了。另一个是，如果变成了单抽词语，抽取式摘要这个问题就退化成了生成式摘要问题，甚至应该叫进化，但是进化的不完全。因为生成式摘要是从一个很庞大的外部词表里面去抽词语，但是抽取式摘要是从原文包含的词语构成的词表里面去抽，从这点上来看，抽取式摘要的灵活性就被大大局限住了。虽然可能对原文中的关键词抽取的会更加准确，但是从整个摘要级别来看，可能整个语句的组织和含义会非常受限，语法也不能够得到保证。所以单做词语级别的抽取式摘要，不如直接做生成式摘要。</p><p>因此，它为生成式摘要方法也算是提供了一些启发，因为原文中的词语构成的词表，对于摘要来说一定是一个核心词表，单从外部词表来抽词语的话，可能会提取不清原文中的关键词。所以就出现了生成式摘要中的一个非常经典的架构，叫做指针生成网络。这个网络它不仅抽取外部词表中的词语，还有一定的概率回过头抽取原文中的关键词，可以说是利用到了抽取式摘要的一些特性，最大限度地保留住了原文中的一些琐碎的信息。</p><h2 id="2-生成式摘要"><a href="#2-生成式摘要" class="headerlink" title="2 生成式摘要"></a>2 生成式摘要</h2><h3 id="2-1-seq2seq-方法-——-初代指针网络"><a href="#2-1-seq2seq-方法-——-初代指针网络" class="headerlink" title="2.1 seq2seq 方法 —— 初代指针网络"></a>2.1 seq2seq 方法 —— 初代指针网络</h3><p>最早的指针-生成网络是在 16 年被提出的，当时的生成式模型主要是基于 RNN 模型。纯 RNN 模型的思路就是，每次解码的时候，都从外部词表中选取最大概率的那一个，作为当前步生成的词语。但是这就带来一个问题，原文中的关键词可能会被忽视掉，一些细节很难被保留。于是出现了指针生成网络。<font color=Red>指针指的是指向原文中的关键词，生成就是从外部词表中选取词语。</font>这篇文章里面除了指针网络还给了这样几个技巧。一个是缩减了词表，只保留了一些高频词和原文中的词语，还有是在词向量中嵌入了一些语言学特征。这些方法对于摘要任务的速度和精度上都有所提升。因为我们知道，相比于抽取式摘要，生成式摘要最大的缺点，一个是训练速度慢，一个是可能语法逻辑不通顺。</p><blockquote><p>Trick 1：LVT 方法 —— 考虑到摘要的多数词来自原文，采用 LVT 方法，用于缩减 decoder 词汇表，只保留一定数量的高频词和原文所包含的词。这样做大大降低了decoder的soft-max计算耗时，并且加速模型收敛(模型只需关注核心词)。<br>Trick 2：词向量融合语言特征 —— 词嵌入中融入了一些语言学特征，包括NER，TF，IDF，以及词性POS。转为离散值，用one-hot向量表示，与词向量一起拼接为一个较长的向量。<br>Trick 3：指针-生成转换器 —— Decoder中，G表示generator(基于Seq2seq生成一个词)，P表示pointer(直接copy原文中的一个词)。当switch开关为1时，采用generator；当switch开关为0时，采用pointer。pointer计算Attention分布，基于Attention分布生成一个pointer位置指针，直接copy原文中与位置指针对应的词即可。</p></blockquote><p><img src="/pic/summarization/%E5%A2%9E%E5%BC%BA%E7%89%88RNN.png" alt="基于 RNN 的 seq2seq 模型"></p><p>指针生成网络的核心思想在于，既能够抽取外部词表中的词语，又能够抽取原文中的词语，这样能够最大限度地去锁住原文中的关键信息。最早的指针生成网络机制是，在每一步解码的时候，有一个 switch机制，先去判定是生成原文中的词语，还是从词表里面选择词语，这就有点像刚刚提到的 swap-net 模型，因为它也是解码的时候用 switch 机制来判定输出整句还是输出词语。之后利用attention 权值来选择最大概率的词语。</p><p><img src="/pic/summarization/%E5%A2%9E%E5%BC%BA%E7%89%88RNN2.png" alt="初代指针网络模型架构"></p><h3 id="2-2-增强版指针-生成网络"><a href="#2-2-增强版指针-生成网络" class="headerlink" title="2.2 增强版指针-生成网络"></a>2.2 增强版指针-生成网络</h3><p>但是初代的指针网络，在选择指针和生成器的时候是分离开来的。也就是说，模型会先判断用外部词表还是原文词表，之后就只盯着某一个具体的词表去抽。在这个基础上，改良版本的指针网络被提出，这个方法的改进之处在于，模型同时去考虑外部的词表和原文的词表，把这两个词表生成词语的概率做一个加权的叠加，来选择最终的生成词语。</p><p>改进后的指针-生成网络，可以看到，每一步解码的时候，原文中的每个词语都有一个 attention 权重，外部词表也会有一个生成的概率分布。之后，通过设置一个概率 p，来衡量到底是多考虑一些原文中的词语，还是外部的词语，将两个概率分布相加之后，得到最终的概率分布。如果是未登录词，概率就设置为 0。相比较最初的指针生成网络而言，这样的生成方式可能会加入一些综合考量的因素在里面，能够在保留原文关键信息的同时，让整个生成的语句更加的连贯，这比单独考虑某一个词表会更好一些。</p><p><img src="/pic/summarization/pointernet.png" alt="改良版指针-生成网络架构"></p><p>之后还提到了一个叫汇聚机制（coverage）的小 trick，它的目的主要是消除一些生成词语的重复现象，比如说再前面某个关键词被提取出来了，尽管很重要，但是他不能被一直重复提取，一是冗余，二是可能会使得其他一样也比较重要的信息被忽略了，目光只盯着这一个关键点了。所以说这个机制就是累加了之前所有的 attention 的得分，并且设置一个惩罚机制，惩罚你提取重复的单词。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
            <tag> 自动摘要生成 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>链表刷题</title>
      <link href="/2022/07/17/%E9%93%BE%E8%A1%A8%E5%88%B7%E9%A2%98/"/>
      <url>/2022/07/17/%E9%93%BE%E8%A1%A8%E5%88%B7%E9%A2%98/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 题库 </tag>
            
            <tag> 链表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>形态学：语言的词汇</title>
      <link href="/2022/07/17/%E5%BD%A2%E6%80%81%E5%AD%A6/"/>
      <url>/2022/07/17/%E5%BD%A2%E6%80%81%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文所述内容参考《语言引论》一书的第三章。</p></blockquote><p>词汇是语言知识的重要一环，并构成我们心理语法的一个组成部分。懂得一个词，就意味着知道某个特定的语音序列与特定的语义相关联。每个词都是一个音义结合的单位，因此我们的心理词库所储存的每个词必须列出其独特的语音表征，决定词的发音，并附上语义。</p><p>音义关系具有任意性。有些词发音相同，但意义不同（例如 bear 和 bare）；另一些词意义相同，但发音不同（例如 sofa 和 couch）。</p><h2 id="1-词典"><a href="#1-词典" class="headerlink" title="1 词典"></a>1 词典</h2><p>绝大多数词典，均以“规范”而非“描写”语词为己任。</p><p>对于词典中的每个词，都需要提供下列信息：（1）拼写；（2）标准发音；（3）一个或多个语义定义；（4）词性。</p><h2 id="2-实义词和功能词"><a href="#2-实义词和功能词" class="headerlink" title="2 实义词和功能词"></a>2 实义词和功能词</h2><ul><li><p>实义词：名词、动词、形容词、副词等我们可以加以考虑的事物、行为、属性、观念等概念，又称开放类词。</p></li><li><p>功能词：连词、介词、冠词、代词等用来界定语法关系，几乎没有语义内容的词汇，又称封闭类词。</p></li></ul><p>人脑处理功能词和实义词的方式不同，脑损害患者和其他有特定语言障碍的病人对于理解功能词，比理解实义词困难得多。</p><p>实义词用来表达语义，功能词则将实义词与更大的语法语境连成一体。两者在语言中各司其职。</p><h2 id="3-语素"><a href="#3-语素" class="headerlink" title="3 语素"></a>3 语素</h2><p>语素是<font color=Red>语法形式的最基本单位</font>，是语音和语义的任意结合体，是一切语言中最小的符号。一个语素可以是单个语音或多个音节，例如 a（单个语音）、child（单个音节）、water（两个音节）等。</p><p>一个词由一个或一个以上的语素构成，例如 im-possible，由两个语素构成。</p><p>用形态学来阐释语言创造性：我们既可以把一个词分解为其组成成分，对整词的词义进行理解或猜测，还可以将语素结合起来创造新词。</p><h3 id="3-1-黏着语素和自由语素"><a href="#3-1-黏着语素和自由语素" class="headerlink" title="3.1 黏着语素和自由语素"></a>3.1 黏着语素和自由语素</h3><p>形态学知识包含两个部分：（1）关于单个语素的知识；（2）关于语素结合规则的知识。</p><ul><li><p>自由语素：本身就构成词的语素，例如 boy、man。</p></li><li><p>黏着语素：永远不能自己构成词，但总是词的组成部分，是词缀。例如 -er、-ist。</p></li></ul><h4 id="3-1-1-前缀和后缀"><a href="#3-1-1-前缀和后缀" class="headerlink" title="3.1.1 前缀和后缀"></a>3.1.1 前缀和后缀</h4><p>词缀根据出现在其他语素的前面还是后面，分为前缀和后缀。</p><ul><li>同一种含义的语素，在不同语言下的规则方式不同。</li></ul><blockquote><p>在英语中，复数语素 -s 是后缀，但在墨西哥的伊斯姆斯-萨波特克语中，复数语素 -ka 是前缀。</p></blockquote><ul><li>同一个语素，在不同语言下含义不同。</li></ul><blockquote><p>语素 -ak 在土耳其语和卡罗克语（太平洋西北部岛屿上的一种美洲土著语）中的意义不同。在土耳其语中，表示将一个动词派生为名词，而在卡罗克语中，则表示将名词派生为副词，表示“在…里面”。</p></blockquote><p>同时进一步说明：<font color=Red>音义关系具有任意性</font>。</p><h4 id="3-1-2-中缀"><a href="#3-1-2-中缀" class="headerlink" title="3.1.2 中缀"></a>3.1.2 中缀</h4><p>一些语言中还存在中缀，即插入其他语素中间的语素。</p><blockquote><p>菲律宾的邦托克语中有这样一种中缀，-um- 插入名词或形容词的第一个辅音之后，用以将名词/形容词转化为动词，例如：fikas（强壮） —— fumikas（是强壮的）。</p></blockquote><p>英语的中缀通常只能将表达猥亵义的整个词插入另一个词中，最常见的 fuckin，插入后例如 un-fuckin-believable。</p><h4 id="3-1-3-外接缀"><a href="#3-1-3-外接缀" class="headerlink" title="3.1.3 外接缀"></a>3.1.3 外接缀</h4><p>一些语言中还存在外接缀，即在同一个词基语素的开头和末尾附加上的语素。</p><blockquote><p>德语中，规则动词的过去分词，通过在动词词根加上前缀 ge- 和后缀 -t 构成。例如：lieb（爱） —— geliebt（爱的过去分词）。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 语言学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 形态学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读 —— 潜在邻近图对抗样本检测</title>
      <link href="/2022/07/17/LNG/"/>
      <url>/2022/07/17/LNG/</url>
      
        <content type="html"><![CDATA[<blockquote><p>本文探讨的论文标题为《Adversarial Example Detection Using Latent Neighborhood Graph》。文章标题开门见山，两个关键部分，一个是对抗样本检测（Adversarial Example Detection），这是描述了这篇文章所要完成的任务，另一个是潜在邻近图（Latent Neighborhood Graph），也就是说，文章很可能是要用一个图模型来完成样本检测的任务。带着这两个关键词，我们来详细分析一下这篇 ICCV 会议上的文章。</p></blockquote><p><img src="/pic/LNG/LNG-%E4%B8%BB.png" alt="LNG 概念图"></p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><h3 id="1-1-任务背景"><a href="#1-1-任务背景" class="headerlink" title="1.1 任务背景"></a>1.1 任务背景</h3><p>任务动机很朴素，当前的深度学习技术被广泛应用在了各个领域里面，但是一些攻击者会对整个深度模型进行操控，通过对模型的输入加入一些微小的扰动，来在人们难以察觉的情况下破坏整个模型的预测结果。这样的事情如果发生在一些安全系统当中，比如身份验证之类的重要环节，就会造成毁灭性的影响。因此深度模型的对抗训练必须被重视。</p><p><img src="/pic/LNG/%E4%BB%BB%E5%8A%A1%E8%83%8C%E6%99%AF.png" alt="一些深度模型微扰的例子，涉及cv、nlp等诸多领域"></p><h3 id="1-2-主流方法"><a href="#1-2-主流方法" class="headerlink" title="1.2 主流方法"></a>1.2 主流方法</h3><p>具体来说，为了让深度模型能够更好地去抵御这些扰动样本，目前比较主流的方法可以被归为两大类：主动防御和被动防御。</p><p>第一种是<font color=Red>主动防御</font>的方法。这种方法在模型训练中较为常见，即我们在训练时考虑到输入扰动的情况，然后手动加入一些对抗样本，这样能够提高模型的一个鲁棒性，而整个解空间更加平滑，而不会因为一个微扰让整个预测结果发生了根本性的变化。但是这种方法有一个非常关键的难点在于，它的训练代价比较大。试想一下，对于一个以及部署好了的已经被投放应用的模型，这时候说要让它的防御能力更强一点，势必要去重新训练整个模型，这个带来的代价是极大的，尤其是在真实的工业场景下。</p><p>另一种相对应的方法是<font color=Red>被动防御</font>方法。这种方式简单明了，不需要在训练时加入对抗样本提高鲁棒性，而是只需要在训练之前，就过滤出样本中的对抗样本即可。这样使得输入样本均为干净样本，训练出来的结果自然符合预期。这种方式对于已部署的系统来说很有价值，因为可以避免模型的重新训练。其次，它还可以帮助输入样本进行一次安全性检查，可以有效拦截一些不安全因素。</p><p>本文主要聚焦于被动防御方法，也就是对抗样本的检测。</p><h3 id="1-3-研究动机"><a href="#1-3-研究动机" class="headerlink" title="1.3 研究动机"></a>1.3 研究动机</h3><p>提到对抗样本检测，那就不得不提一下 Dknn 这个深度模型，这也是本文idea的一个核心的参考架构。</p><p>Dknn 是检测对抗样本的一个深度方法，它采用了 knn 的算法思想。我们要判断某个中心样本是否是对抗样本，首先将所有样本输入模型，之后在网络的每一层，每个样本都会得到一个 embedding。之后，沿用 knn 的思想，选择这个中心样本最相近的 k 个邻居，并将这 k 个邻居和中心样本的类别进行比较。如果这些样本基本属于同一类，说明这个中心样本不太可能是对抗样本，如果它们之间对应的类别有明显的不一致，例如，这个中心样本的类别是熊猫，但是它的 k 个邻居里面有一半是表示汽车的样本，那么这时候就可以怀疑这个中心样本可能存在问题。</p><p><img src="/pic/LNG/dknn.png" alt="DkNN 架构的核心思路示意图"></p><p>受到 Dknn 的启发，作者认为，Dknn 在检测对抗样本的时候，是利用了输入样本和它邻近样本之间的联系来判断的，那么可以利用一个动态的图结构，来更加具体地表示这种邻近关系。于是诞生了本文的核心模型，也就是 latent neighboorhood graph（以下简称LNG）。图模型的好处在于，它不光能够表示中心节点和它的邻近点，还能够通过建边来表示点和点之间的关系，这是 Dknn 方法做不到的。其次，把图模型构建出来之后，可以转化成一个二分类问题，利用图神经网络等方法进行分类。</p><h3 id="1-4-优势对比"><a href="#1-4-优势对比" class="headerlink" title="1.4 优势对比"></a>1.4 优势对比</h3><table>    <tr>        <td>LNG</td><td>Dknn</td>    </tr>    <tr>        <td>cover multi-hop heighbors of inputs’ local manifolds</td><td>only cover inputs’ local manifolds</td>    </tr>        <tr>        <td>richer information, aggregate the connectivity learned on the embedding space</td><td>only cover the information of class labels</td>    </tr>        <tr>        <td>incorporate both adversarial and benign neighbors</td><td>only utilize benign neighbors</td>    </tr></table><p>相比于dknn，LNG 的优势在于：<br>（1）图模型的信息表达更加丰富，它不光有节点的信息，也就是中心节点的邻居信息，还聚合了边的信息，也就是节点和节点之间的联系。我们可以通过距离来量化点和点之间的关联。<br>（2）LNG 引入了邻居多跳机制，可以把中心节点的邻居的邻居也给选择进来，让整个图模型的信息进一步丰富起来。</p><h2 id="2-方法架构"><a href="#2-方法架构" class="headerlink" title="2 方法架构"></a>2 方法架构</h2><h3 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1 概述"></a>2.1 概述</h3><p>LNG 的方法流程如下所示：</p><p><img src="/pic/LNG/%E6%B5%81%E7%A8%8B.png" alt="LNG 方法流程图"></p><p>第一步，从完整的输入样本中提取出一个子集，称作是参考数据集，这个数据集的是用来构建图模型中的结点的，也就是图模型的结点范围不会超出这个参考数据集。</p><p>第二步，构建完数据集之后需要建图。建图分成两部分，首先是选择节点，其次是将点和点之间构建无向边，从而形成最终的图模型。</p><p>第三步，二分类问题，也就是判断中心节点是否是对抗样本。</p><h3 id="2-2-参考数据集"><a href="#2-2-参考数据集" class="headerlink" title="2.2 参考数据集"></a>2.2 参考数据集</h3><p>首先是参考数据集的构建。对于一个完整的数据集，从中提取出一个样本作为中心样本，我们需要判断这个样本是良性的还是对抗样本。之后，从这个完整的数据集中提取出一个样本子集，作为候选样本。</p><p>接下来有两种数据集的构建方法，第一种是直接把样本子集和中心样本给合起来，作为一个参考数据集，称为良性数据集。第二种是先对这个样本子集进行数据增强，也就是子集中的每个样本都利用对抗算法获得一个对抗样本，之后把扩充后的样本子集和中心样本合并起来，作为一个新的参考数据集，称为对抗数据集。</p><p><img src="/pic/LNG/reference_dataset.png" alt="参考数据集构建流程（自己画的）"></p><h3 id="2-3-潜在邻近图"><a href="#2-3-潜在邻近图" class="headerlink" title="2.3 潜在邻近图"></a>2.3 潜在邻近图</h3><p>接下来是核心步骤 —— 构图。</p><h4 id="2-3-1-结点构造"><a href="#2-3-1-结点构造" class="headerlink" title="2.3.1 结点构造"></a>2.3.1 结点构造</h4><p>首先是图节点的选择。对于中心节点来说，从参考数据集中选出最近的 k 个节点作为邻居。其次，引入了多跳邻居的思想，不仅可以选择中心节点的 k 邻近节点，还可以选择邻居的 k 邻近节点。具体来说，设置一个阈值 L，表示可以迭代的邻居次数。例如 L=2，就可以选择中心节点的邻居，这是一轮，以及邻居的邻居，这是第二轮，那 L=3,4 以此类推，相当于一个广度优先搜索的思想。但是所有选出的点不会超出参考数据集的范围。</p><h4 id="2-3-2-边构造"><a href="#2-3-2-边构造" class="headerlink" title="2.3.2 边构造"></a>2.3.2 边构造</h4><p>接下来是节点之间边的表示，主要还是利用欧氏距离来进行表征，并且为了归一化尺度，用 sigmoid 函数做了一个映射，将边权映射到0到1的区间上。此外，这个 sigmoid 函数中有两个参数 $t$ 和 $\theta$，是放在网络中用来学习的参数。</p><p>$$<br>A_{i,j} = \frac{1}{1 + e^{-t \cdot d(i,j) + \theta}}<br>$$</p><h3 id="2-4-图分类器"><a href="#2-4-图分类器" class="headerlink" title="2.4 图分类器"></a>2.4 图分类器</h3><p>最后一部分是图分类器，用来判定中心节点是良性样本还是对抗样本。文章采用的是经典的图注意力网络模型 GAT，模型的输入是所有样本的 embedding 以及邻接矩阵，输出是一个二维向量。</p><h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h2><h3 id="3-1-实验设置"><a href="#3-1-实验设置" class="headerlink" title="3.1 实验设置"></a>3.1 实验设置</h3><p>实验共采用了 5 种经典的对抗样本生成方法，包括 FGSM，PGD 等，这是在构建参考数据集的时候，对原数据做数据增强用的。Baseline 主要用了 DKNN 和 KNN 架构，以及 LID 和Hu 等人提出的方法。数据集采用了图像领域经典的几个数据集，包括有 CIFAR-10，ImageNet 和 STL-10。</p><h3 id="3-2-实验细节"><a href="#3-2-实验细节" class="headerlink" title="3.2 实验细节"></a>3.2 实验细节</h3><p>对于每个数据集，分成三个部分：训练集、参考集和测试集，这里的参考集是用来选取超参数的，比如多跳邻居机制里面的参数 L。验证集是从测试集里单独划分出来的，例如对于CIFAR-10 数据集，本实验从测试集中，每个类别随机选了 100 个样本组成了新的验证集。此外，同一个数据集上只能用一种对抗攻击方法，以及在主实验中，使用的是加入对抗样本的参考数据集。</p><p>超参数设置方面，主要是多跳邻居机制的阈值 L 和 knn 算法里面的 k。文章设置了 L=2，k=5。还有一个是 baseline 里面的dknn算法，也要有具体 k 值的设置。实验在三个数据集上的 k 值设置分别为200，40 和 40。</p><p>最后是对于 LNG 图的输出结果的处理。在训练过程中，所有的边的结果是通过欧氏距离和sigmoid 映射来产生的。从模型输出之后，所有的边的信息又被映射为一个 0-1 空间。具体来说，如果这条边的大小大于某个阈值 t，那么认为这条边存在，赋值为 1，否则认为不存在，赋值为 0。</p><h3 id="3-3-threat-model"><a href="#3-3-threat-model" class="headerlink" title="3.3 threat model"></a>3.3 threat model</h3><h4 id="3-3-1-白盒测试"><a href="#3-3-1-白盒测试" class="headerlink" title="3.3.1 白盒测试"></a>3.3.1 白盒测试</h4><h4 id="3-3-2-黑盒测试"><a href="#3-3-2-黑盒测试" class="headerlink" title="3.3.2 黑盒测试"></a>3.3.2 黑盒测试</h4><h3 id="3-4-主实验"><a href="#3-4-主实验" class="headerlink" title="3.4 主实验"></a>3.4 主实验</h3><h4 id="3-4-1-检测已知攻击"><a href="#3-4-1-检测已知攻击" class="headerlink" title="3.4.1 检测已知攻击"></a>3.4.1 检测已知攻击</h4><h4 id="3-4-2-检测未知攻击"><a href="#3-4-2-检测未知攻击" class="headerlink" title="3.4.2 检测未知攻击"></a>3.4.2 检测未知攻击</h4><h3 id="3-5-消融实验"><a href="#3-5-消融实验" class="headerlink" title="3.5 消融实验"></a>3.5 消融实验</h3><h3 id="3-6-图的拓扑结构讨论"><a href="#3-6-图的拓扑结构讨论" class="headerlink" title="3.6 图的拓扑结构讨论"></a>3.6 图的拓扑结构讨论</h3>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 对抗机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文精读 —— BERT 预训练语言模型</title>
      <link href="/2022/07/17/bert/"/>
      <url>/2022/07/17/bert/</url>
      
        <content type="html"><![CDATA[<p><img src="/pic/bert.png" alt="Google 公司推出的 Bert 预训练语言模型"></p><blockquote><p>本文所探讨的论文标题为 《BERT：Pre-training of Deep Bidirectional Transformers for Language Understanding》。BERT 可以称作是预训练语言模型的开山之作了，和 OpenAI 的 GPT 模型是同时期的产物，但性能优于 GPT。BERT 模型基于 Transformer 架构实现，是一种全新的双向编码器语言模型。与ELMo、GPT等单向语言模型不同，BERT 旨在构建一个双向的语言模型，来更好地捕获语句间的上下文语义，使其在更多的下游任务上具有更强的泛化能力。因此，预训练完成的 BERT 模型被迁移到下游任务时，只需要在添加一个额外的输出层便可以进行微调，例如问答和语言推理任务，并不需要针对具体的任务进行模型架构的修改。BERT 模型在概念上简单却具有强大的性能，它在11项经典的自然语言处理任务上取得了最优的效果，包括将 GLUE 数据集的得到提升至80.5%（相比于之前的最优模型提升了7.7%），将SQuAD v1.1问答测试数据集的 F1 值至 93.2（提升了1.5个点），以及将SQuAD v2.0 数据集的 F1 值到 83.1（提升了5.1个点）。</p></blockquote><h2 id="1-研究概述"><a href="#1-研究概述" class="headerlink" title="1 研究概述"></a>1 研究概述</h2><h3 id="1-1-研究背景"><a href="#1-1-研究背景" class="headerlink" title="1.1 研究背景"></a>1.1 研究背景</h3><p>大规模标注语料库的匮乏，成为了制约NLP（Natural Language Processing）领域发展的一大重要因素。为了使NLP模型能够充分地利用海量廉价的无标注数据信息，预训练语言模型（Pre-trained Models, PTMs）应运而生。通过模型预训练，我们可以从海量数据集中初步获取潜在的特征规律，再将这些共性特征移植到特定的任务模型中去，将学习到的知识进行迁移。具体来说，我们需要将模型在一个通用任务上进行参数训练，得到一套初始化参数，再将该初始化模型放置到具体任务中，通过进一步的训练来完成更加特殊的任务。预训练模型的推广，使得许多NLP任务的性能获得了显著提升，它为模型提供了更好的初始化参数，大大提高了其泛化能力。至此，NLP领域进入了一个新的研究阶段。</p><h3 id="1-2-问题分析与解决"><a href="#1-2-问题分析与解决" class="headerlink" title="1.2 问题分析与解决"></a>1.2 问题分析与解决</h3><p>当前的预训练模型主要分为基于特征和微调两大类，但它们大都基于单向的语言模型来进行语言学习表征，这使得许多句子级别的下游任务无法达到最优的训练效果。因此，本文提出了名为BERT的双向预训练表征模型，很大程度上缓解了单向模型带来的约束。同时，引入了“完形填空”和“上下句匹配”分别作为单词级别和句子级别的两大通用任务，对BERT模型进行训练。实验表明， BERT模型的应用使得当前的11个NLP任务均取得了SOTA的效果。</p><h3 id="1-3-相关工作"><a href="#1-3-相关工作" class="headerlink" title="1.3 相关工作"></a>1.3 相关工作</h3><h4 id="1-3-1-基于特征的无监督方法"><a href="#1-3-1-基于特征的无监督方法" class="headerlink" title="1.3.1 基于特征的无监督方法"></a>1.3.1 基于特征的无监督方法</h4><p>基于特征的方法主要是指单词嵌入表征学习。首先将文本级别的输入输出为特征向量的形式，再将预训练好的嵌入向量作为下游任务的输入。</p><p>词嵌入向量[1-5]是单词表征学习的最细粒度。通过统计学习或深度学习方法，文本中的单词被映射至向量空间中的密集向量。随着人们对于文本连贯性的关注，句子[6-7]和段落[8]级别的嵌入表征被提出，更多的数据特征被获取，进一步提升了预训练效果。相比于从头开始的词嵌入训练，预训练的引入对于各类任务的性能具有显著的提升效果。 </p><p>上述模型均从单词拼写的层面进行了表征学习，并没有考虑单词在句中的使用形式。Matthew Peters等人在此基础上提出了名为ELMo[9]的语境字词嵌入表征法，该模型会根据句子的上下文，对同一个单词返回特定语境下不同的嵌入表征。在一些NLP基准任务上[10]，例如情感分析[11]、问答系统[12]、命名实体识别[13]，ELMo均取得了最优性能。这也是NLP领域中第一个开始关注上下文的预训练模型，为本文BERT模型的提出奠定了坚实的基础。</p><h4 id="1-3-2-基于微调的无监督方法"><a href="#1-3-2-基于微调的无监督方法" class="headerlink" title="1.3.2 基于微调的无监督方法"></a>1.3.2 基于微调的无监督方法</h4><p>基于微调的方法主要是指，我们在某些通用任务上预训练完成的模型架构，可以被直接复制到下游任务中，下游任务根据自身需求修改目标输出，并利用该模型进行进一步的训练。也就是说，下游任务使用了和预训练相同的模型，但是获得了一个较优的初始化参数，我们需要对这些参数进行微调，从而在特殊任务上获得最优性能。基于该方法，Alec Radford等人提出了OpenAI GPT[14]模型，它在许多句子级别的任务上获得了SOTA效果。</p><h4 id="1-3-3-基于有监督数据的迁移学习"><a href="#1-3-3-基于有监督数据的迁移学习" class="headerlink" title="1.3.3 基于有监督数据的迁移学习"></a>1.3.3 基于有监督数据的迁移学习</h4><p>我们也可以基于存在大量有监督数据集的任务来获取预训练模型，例如自然语言推理和机器翻译。预训练的思想也被广泛应用到CV领域， Jason Yosinski在ImageNet数据集[15]上获取的预训练模型[16]，在许多下游任务中都取得了较优的性能。</p><h2 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2 解决方法"></a>2 解决方法</h2><h3 id="2-1-问题描述"><a href="#2-1-问题描述" class="headerlink" title="2.1 问题描述"></a>2.1 问题描述</h3><p>在BERT出现之前，已有的预训练语言模型大多为单向模型架构。例如OpenAI 推出的GPT模型[14]，便是引入了Transformer Decoder层[2]中的掩码注意力机制，使得模型能够充分学习上下文语义。然而，单向模型架构仍然限制了预训练模型在NLP任务上的泛化能力，诸多NLP任务难以从单向架构中学习到更多有用的特征，例如问答系统[12]。因此，需要继续对当前的预训练架构进行优化，使得其能够适应更多种类的任务，增强其在NLP领域的通用性。</p><h3 id="2-2-创新思想"><a href="#2-2-创新思想" class="headerlink" title="2.2 创新思想"></a>2.2 创新思想</h3><p>BERT(Bidirectional Encoder Representation from Transformers)是2018年10月由Google AI研究院提出的一种预训练模型，它创造性地将Transformer中的Encoder架构引入预训练模型中，成为第一个使用双向表征的预训练语言模型。同时，为了适应该双向架构，BERT引入了两项新的NLP任务——完形填空和上下句匹配，来捕获词语级别和句子级别的表征，并使之具有更强的泛化能力。</p><h3 id="2-3-具体方法"><a href="#2-3-具体方法" class="headerlink" title="2.3 具体方法"></a>2.3 具体方法</h3><p>BERT整体框架包含Pre-training和Fine-tuning两个阶段，如图2.1所示。Pre-training阶段,模型首先在设定的通用任务上，利用无标签数据进行训练。训练好的模型获得了一套初始化参数之后，再到Fine-tuning阶段，模型被迁移到特定任务中，利用有标签数据继续调整参数，直至在特定任务上重新收敛。</p><p><img src="/pic/bert/%E6%9E%B6%E6%9E%84.png" alt="BERT的pre-training和fine-tuning架构"></p><h4 id="2-3-1-模型架构"><a href="#2-3-1-模型架构" class="headerlink" title="2.3.1 模型架构"></a>2.3.1 模型架构</h4><p>BERT模型采用了Transformer中的Encoder架构，通过引入多头注意力机制，将Encoder块进行堆叠，形成最终的BERT架构。为了适应不同规模的任务，BERT将其结构分为了base和large两类。较小规模的base结构含有12个Encoder单元，每个单元中含有12个Attention块，词向量维度为768；较大规模的large结构含有24个Encoder单元，每个单元中含有16个Attention块，词向量维度为1024。通过使用Transformer作为模型的主要框架，BERT能够更彻底地捕获语句中的双向关系，极大地提升了预训练模型在具体任务中的性能。</p><p>BERT 模型的输入由三部分组成。除了传统意义上的 token 词向量外，BERT 还引入了位置词向量和句子词向量。位置词向量的思想与 Transformer 一致，但 BERT 并未使用其计算公式，而是随机初始化后放入模型一同训练；句子词向量实质上是一个0-1表征，目的是区分输入段落中的上下句。这三种不同意义的词向量相加，构成了最终输入模型的词向量。</p><p><img src="/pic/bert/%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5.png" alt="BERT的输入格式"></p><h4 id="2-3-2-预训练"><a href="#2-3-2-预训练" class="headerlink" title="2.3.2 预训练"></a>2.3.2 预训练</h4><p>BERT的预训练（pre-training）部分使用了完形填空和上下句匹配两项无监督任务。“完形填空”代表了词语级别的预训练任务，该任务对输入句子中若干随机位置的字符进行遮盖，并利用上下文语境对遮盖字符进行预测。“上下句匹配”代表了句子级别的预训练任务，该任务给出两个句子，利用句子之间的语义连贯性判定这两个句子是否存在上下句关系。这两项预训练任务对于大量NLP任务的架构具有更好的代表性，同时也更能匹配模型本身的双向架构，对模型的泛化能力有着巨大的提升帮助。</p><h4 id="2-3-3-微调"><a href="#2-3-3-微调" class="headerlink" title="2.3.3 微调"></a>2.3.3 微调</h4><p>训练具体任务时，我们只需将具体任务中的输入输出传入预训练完成的 BERT 模型，继续调整参数直至模型再次收敛。该过程称为微调（fine-tuning）。相比于预训练来说，微调的代价是极小的。在大部分NLP任务中，我们只需要在GPU上对模型进行几个小时的微调，便可使模型在具体任务上收敛，完成训练。</p><h2 id="3-实验分析与结论"><a href="#3-实验分析与结论" class="headerlink" title="3 实验分析与结论"></a>3 实验分析与结论</h2><h3 id="3-1-实验设置"><a href="#3-1-实验设置" class="headerlink" title="3.1 实验设置"></a>3.1 实验设置</h3><p>本文将BERT模型迁移至11个NLP基准任务上进行了微调训练，均取得了SOTA的效果。另外，为了探究模型的不同组成部分对整体性能的影响，本文还进行了若干消融实验，对BERT的预训练任务、模型规模等要素进行了实验评估，充分论证了双向模型的重要性。</p><h3 id="3-2-数据集和主实验分析"><a href="#3-2-数据集和主实验分析" class="headerlink" title="3.2 数据集和主实验分析"></a>3.2 数据集和主实验分析</h3><p>BERT共实现了对于11个NLP基准任务的微调训练，共对应4个数据集。本部分将详细描述各个数据集及其对应的基准任务，并介绍每个数据集上的参数设置和实现细节，以及对主实验的结果进行简要分析。</p><h4 id="3-2-1-GLUE"><a href="#3-2-1-GLUE" class="headerlink" title="3.2.1 GLUE"></a>3.2.1 GLUE</h4><p>GLUE[17]数据集共收集了包含自然语言推理、语义相似性判断等任务在内的9项NLP基准任务，并与OpenAI GPT、ELMo等性能较优的基准模型进行了结果对比。实验微调了3个epoch，将batch size设置为32，并利用验证集选择最佳学习率。实验结果如表3.1所示，结果表明，相较于当前性能最优的模型，BERTBASE 和 BERTLARGE 模型在所有任务上的性能表现均获得了较为可观的提升，平均准确度分别超过SOTA结果4.5%和7.0%。同时，BERTLARGE 在所有任务上的性能均超出了BERTBASE ，且在少样本数据集上的性能尤为突出。</p><p><img src="/pic/bert/GLUE%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="表3.1 GLUE数据集（九项自然语言理解或生成任务）的实验结果"></p><h4 id="3-2-2-SQuAD-v1-1"><a href="#3-2-2-SQuAD-v1-1" class="headerlink" title="3.2.2 SQuAD v1.1"></a>3.2.2 SQuAD v1.1</h4><p>SQuAD v1.1[12]是一个问答任务数据集，共收集了100k组问答语句对。给定一个问句和一个包含答案的文段，需要提取出文段中该问句对应正确答案的文本范围。实验微调了3个epoch，将batch size设置为32，并将学习率固定为5e-5。实验结果如表3.2所示，结果表明，对于集成模型和单一模型这两种框架而言，BERT相比于现有的最优模型在F1指标上分别获得了1.5%和1.3%的提升，且BERT单一模型的性能甚至超过了当前最优的集成模型的性能。</p><p><img src="/pic/bert/SQuADv1.1%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="表3.2 SQuAD v1.1数据集（基础版问答任务）的实验结果"></p><h4 id="3-2-3-SQuAD-v2-0"><a href="#3-2-3-SQuAD-v2-0" class="headerlink" title="3.2.3 SQuAD v2.0"></a>3.2.3 SQuAD v2.0</h4><p>SQuAD v2.0是在SQuAD v1.1数据集上的一个拓展，该数据集中所提供的文段中，有一定的可能性不存在对应答案，从而使得问题更切合实际。实验微调了2个epoch，将batch size设置为48，并将学习率固定为5e-5。实验结果如表3.3所示，结果表明，与先前的若干工作[18, 19]相比，BERT相较于现有的最优模型，在F1指标上获得了5.1%的提升。</p><p><img src="/pic/bert/SQuADv2.0%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="表3.3 SQuAD v2.0数据集（拓展版问答任务）的实验结果"></p><h4 id="3-2-4-SWAG"><a href="#3-2-4-SWAG" class="headerlink" title="3.2.4 SWAG"></a>3.2.4 SWAG</h4><p>SWAG[20]是一个具有对抗性生成情形的自然语言推理数据集，它包含了113k组句子对。通过理解给定的句子，我们需要从对应的四个句子中选择最有可能延续在该句子之后的选项。实验构建了四个输入序列，每个序列包含了给定句子和可能的延续句子之间的连接。同时，还引入了一个参数向量，它与每个句子开头的 [CLS] 符号之间的点积表示该选项的最终得分。实验微调了3个epoch，将batch size设置为16，并将学习率固定为2e-5。实验结果如表3.4所示，结果表明，BERTLARGE的性能相较于ESIM+ELMo提升了27.1%，相较于OpenAI GPT提升了8.3%。</p><p><img src="/pic/bert/SWAG%E6%95%B0%E6%8D%AE%E9%9B%86.png" alt="表3.4 SWAG数据集（对抗文本生成任务）的实验结果"></p><h3 id="3-3-消融实验及结果分析"><a href="#3-3-消融实验及结果分析" class="headerlink" title="3.3 消融实验及结果分析"></a>3.3 消融实验及结果分析</h3><p>本部分对BERT模型的多个部分进行了消融实验研究，旨在探寻它们对于整体模型的重要程度。</p><h4 id="3-3-1-预训练任务"><a href="#3-3-1-预训练任务" class="headerlink" title="3.3.1 预训练任务"></a>3.3.1 预训练任务</h4><p>本部分通过对 BERT 预训练任务进行消融，旨在论证 BERT 深度双向模型这一创新思想的重要性。实验共设置了两组消融，其中一组使用双向完形填空任务但不使用上下句预测任务，另一组同样不使用上下句预测任务，但实现完形填空任务时采用从左到右的标准模型。文章首先探究了上下句预测任务的取消带来的影响，发现其严重降低了 QNLI，MNLI 和 SQuAD 1.1 这三个任务的性能。其次，通过改变完形填空任务的训练方式，来探究双向训练带来的影响。实验结果如表 3.5 所示，结果表明，在所有任务上，从左到右的单向模型性能都收获了更差的效果，在 MRPC 和 SQuAD 这两个任务上尤为显著。</p><p><img src="/pic/bert/%E5%AF%B9%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1%E8%BF%9B%E8%A1%8C%E6%B6%88%E8%9E%8D%E7%9A%84%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C.png" alt="表3.5 对预训练任务进行消融的实验结果"></p><h4 id="3-3-2-模型规模"><a href="#3-3-2-模型规模" class="headerlink" title="3.3.2 模型规模"></a>3.3.2 模型规模</h4><p>本部分旨在探究模型大小对微调任务准确度的影响。实验设置了若干具有不同层数、隐层维度以及注意力头数目的模型，并在 GLUE 数据集上进行了微调训练。实验结果如表 3.6 所示，结果表明，即使是在有标签数据量较小的数据集上，随着模型规模的提高，任务的准确度都获得了显著的提升。现有的最大规模的 Transformer 模型[21]具有 235M 的参数量，而 BERTLARGE 进一步将参数量增加至 340M，并且使性能获得了更大的提升。此实验进一步论证了，如果模型已经经过了充分的预训练，那么当将模型缩放到一个极限的规模尺寸时，仍然能够在小规模的微调任务上产生较大的改进。</p><p><img src="/pic/bert/%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%A7%84%E6%A8%A1%E8%BF%9B%E8%A1%8C%E6%B6%88%E8%9E%8D%E7%9A%84%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C.png" alt="表3.6 对模型规模进行消融的实验结果"></p><h3 id="3-4-实验总结"><a href="#3-4-实验总结" class="headerlink" title="3.4 实验总结"></a>3.4 实验总结</h3><p>实验结果表明，深层的双向语言模型能够极大地改善 NLP 任务的性能。同时，预训练模型的迁移学习，逐渐成为语言理解系统中不可或缺的一部分，它甚至能够使得一些低资源的任务从深度单向架构中受益。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]    Brown P F, Della Pietra V J, Desouza P V, et al. Class-based n-gram models of natural language[J]. Computational linguistics, 1992, 18(4): 467-480.<br>[2]    Ando R K, Zhang T, Bartlett P. A framework for learning predictive structures from multiple tasks and unlabeled data[J]. Journal of Machine Learning Research, 2005, 6(11).<br>[3]    Blitzer J, McDonald R, Pereira F. Domain adaptation with structural correspondence learning[C]//Proceedings of the 2006 conference on empirical methods in natural language processing. 2006: 120-128.<br>[4]    Mikolov T, Sutskever I, Chen K, et al. Distributed representations of words and phrases and their compositionality[J]. Advances in neural information processing systems, 2013, 26.<br>[5]    Pennington J, Socher R, Manning C D. Glove: Global vectors for word representation[C]//Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014: 1532-1543.<br>[6]    Kiros R, Zhu Y, Salakhutdinov R R, et al. Skip-thought vectors[J]. Advances in neural information processing systems, 2015, 28.<br>[7]    Logeswaran L, Lee H. An efficient framework for learning sentence representations[J]. arXiv preprint arXiv:1803.02893, 2018.<br>[8]    Le Q, Mikolov T. Distributed representations of sentences and documents[C]//International conference on machine learning. PMLR, 2014: 1188-1196.<br>[9]    Peters M E, Ammar W, Bhagavatula C, et al. Semi-supervised sequence tagging with bidirectional language models[J]. arXiv preprint arXiv:1705.00108, 2017.<br>[10]    Peters M, Neumann M, Iyyer M, et al. Deep contextualized word representations[A]. Conference of the North American Chapter of the Association for Computational Linguistics[C]. New Orleans, Louisiana, Association for Computational Linguistics, 2018a: 2227-2237.<br>[11]    Socher R, Perelygin A, Wu J, et al. Recursive deep models for semantic compositionality over a sentiment treebank[C]//Proceedings of the 2013 conference on empirical methods in natural language processing. 2013: 1631-1642.<br>[12]    Rajpurkar P, Zhang J, Lopyrev K, et al. Squad: 100,000+ questions for machine comprehension of text[J]. arXiv preprint arXiv:1606.05250, 2016.<br>[13]    Sang E F, De Meulder F. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition[J]. arXiv preprint cs/0306050, 2003.<br>[14]    Radford A, Narasimhan K, Salimans T, et al. Improving language understanding with unsupervised learning[J]. 2018.<br>[15]    Deng J, Dong W, Socher R, et al. Imagenet: A large-scale hierarchical image database[C]//2009 IEEE conference on computer vision and pattern recognition. Ieee, 2009: 248-255.<br>[16]    Yosinski J, Clune J, Bengio Y, et al. How transferable are features in deep neural networks?[J]. Advances in neural information processing systems, 2014, 27.<br>[17]    Wang A, Singh A, Michael J, et al. GLUE: A multi-task benchmark and analysis platform for natural language understanding[J]. arXiv preprint arXiv:1804.07461, 2018.<br>[18]    Sun F, Li L, Qiu X, et al. U-net: Machine reading comprehension with unanswerable questions[J]. arXiv preprint arXiv:1810.06638, 2018.<br>[19]    Wang W, Yan M, Wu C. Multi-granularity hierarchical attention fusion networks for reading comprehension and question answering[J]. arXiv preprint arXiv:1811.11934, 2018.<br>[20]    Zellers R, Bisk Y, Schwartz R, et al. Swag: A large-scale adversarial dataset for grounded commonsense inference[J]. arXiv preprint arXiv:1808.05326, 2018.<br>[21]    Al-Rfou R, Choe D, Constant N, et al. Character-level language modeling with deeper self-attention[C]//Proceedings of the AAAI conference on artificial intelligence. 2019, 33(01): 3159-3166.</p>]]></content>
      
      
      <categories>
          
          <category> 论文精读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022计算机保研记录 | 夏令营经历分享</title>
      <link href="/2022/07/16/%E4%BF%9D%E7%A0%941/"/>
      <url>/2022/07/16/%E4%BF%9D%E7%A0%941/</url>
      
        <content type="html"><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="抱歉，这个密码看着不太对，请再试试。" data-whm="抱歉，这个文章不能被纠正，不过您还是能看看解密后的内容。">  <script id="hbeData" type="hbeData" data-hmacdigest="f8832000c7cf3d5d195d45783a5392a77895c98ea50f08eca6819ac27e6cbafe">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</script>  <div class="hbe hbe-content">    <div class="hbe hbe-input hbe-input-default">      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">        <span class="hbe hbe-input-label-content hbe-input-label-content-default">您好，这里需要密码。</span>      </label>    </div>  </div></div><script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      
      
      <categories>
          
          <category> 保研 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 保研夏令营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hpctoolkit安装与使用</title>
      <link href="/2022/01/19/hpctoolkit/"/>
      <url>/2022/01/19/hpctoolkit/</url>
      
        <content type="html"><![CDATA[<p><img src="/pic/hpctoolkit.png" alt="hpctoolkit 工作流程图"></p><h2 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h2><!-- We now use Spack for building HPCToolkit's prerequisites (replacing the old hpctoolkit externals). You can install HPCToolkit with the "One Button" spack install hpctoolkit method. --><p>本文采用 Spack 来构建 HPCToolkit 的 prerequisites（不使用原有的 hpctoolkit 外部组件）。 </p><ul><li>clone spack 对应的 github 仓库</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">git clone https:&#x2F;&#x2F;github.com&#x2F;spack&#x2F;spack<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>创建环境变量</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">export SPACK_ROOT&#x3D;&#96;pwd&#96;&#x2F;spackexport PATH&#x3D;$&#123;SPACK_ROOT&#125;&#x2F;bin:$PATH<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><ul><li>刷新 shell 环境</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">source $&#123;SPACK_ROOT&#125;&#x2F;share&#x2F;spack&#x2F;setup-env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>检测安装环境</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spack compiler find<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>安装</li></ul><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">spack install hpctoolkit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="常见-bug"><a href="#常见-bug" class="headerlink" title="常见 bug"></a>常见 bug</h2><p><img src="/pic/hpctoolkit/bug1.png" alt="bug 1"></p><p><img src="/pic/hpctoolkit/bug2.png" alt="bug 2"></p><ul><li><p>原因</p><p>  未设置 fortran 编译环境</p></li><li><p>解决方法</p><p>  将安装环境加入 <code>/.spack/linux/compilers.yaml</code> 文件中</p></li></ul><p><img src="/pic/hpctoolkit/bug.png" alt="解决方案"></p>]]></content>
      
      
      <categories>
          
          <category> 并行计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高性能分析工具 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
